# üî¨ Experimentos de Modelos Edge

Sistema completo de experimentaci√≥n para seleccionar la mejor arquitectura liviana para edge computing.

---

## üéØ Objetivo

Determinar cu√°l arquitectura es la **mejor** para deployment en dispositivos edge bas√°ndose en:

1. **Precisi√≥n global ‚â• 85%**
2. **Recall por clase ‚â• 0.80**
3. **Tama√±o del modelo** (menor es mejor)
4. **Balance precisi√≥n/tama√±o** (efficiency score)

---

## üèóÔ∏è Arquitecturas Evaluadas

| Modelo | Par√°metros | Tama√±o | Caracter√≠sticas |
|--------|------------|--------|-----------------|
| **MobileNetV3Small** | ~2.5M | ~10MB | Ultra-liviano, latencia m√≠nima |
| **MobileNetV3Large** | ~5.4M | ~21MB | Balance tama√±o/precisi√≥n |
| **EfficientNet-Lite B0** | ~4.7M | ~18MB | Optimizado para mobile |
| **EfficientNet-Lite B1** | ~5.4M | ~22MB | Mejor precisi√≥n |
| **EfficientNet-Lite B2** | ~6.1M | ~24MB | Mayor precisi√≥n |
| **MobileViT** | ~6.4M | ~25MB | Vision Transformer m√≥vil |
| **PMVT** | ~6M | ~24MB | Optimizado para plantas |

---

## üöÄ Uso R√°pido (Docker)

### 1. Entrenar Todas las Arquitecturas

```bash
# Desde el root del proyecto
docker-compose --profile edge-experiments up
```

Esto ejecutar√° autom√°ticamente:
1. Entrenamiento de los 7 modelos
2. Comparaci√≥n de resultados
3. Selecci√≥n del mejor modelo
4. Generaci√≥n de `best_edge_model.json`

**Tiempo estimado:** 3-5 horas (dependiendo de tu hardware)

### 2. Ver Resultados en MLflow

```bash
# Iniciar MLflow UI
docker-compose --profile mlflow up -d

# Acceder a:
open http://localhost:5000
```

Filtra por experimento: **edge_models_comparison**

---

## üìä Scripts Disponibles

### `train_edge_model.py`

Entrena un modelo espec√≠fico.

```bash
# Ejemplo: Entrenar MobileNetV3Small
docker-compose run --rm training python experiments/edge_models/train_edge_model.py \
  --model MobileNetV3Small \
  --epochs 30 \
  --lr 0.001 \
  --dropout 0.3

# Con fine-tuning
docker-compose run --rm training python experiments/edge_models/train_edge_model.py \
  --model PMVT \
  --epochs 30 \
  --fine-tune \
  --fine-tune-epochs 10
```

**Opciones:**
- `--model`: Modelo a entrenar (ver lista arriba)
- `--lr`: Learning rate (default: 0.001)
- `--dropout`: Dropout rate (default: 0.3)
- `--epochs`: N√∫mero de √©pocas (default: 30)
- `--batch-size`: Tama√±o del batch (default: 32)
- `--fine-tune`: Activar fine-tuning
- `--fine-tune-epochs`: √âpocas de fine-tuning (default: 10)

### `train_all_models.py`

Entrena todas las arquitecturas secuencialmente.

```bash
docker-compose run --rm training python experiments/edge_models/train_all_models.py
```

Cada modelo se entrena con hiperpar√°metros optimizados predefinidos.

### `compare_models.py`

Compara todos los modelos entrenados.

```bash
docker-compose run --rm training python experiments/edge_models/compare_models.py
```

Genera:
- Tabla comparativa en consola
- Archivo `comparison_results.csv`
- An√°lisis de mejores modelos por criterio

### `select_best_model.py`

Selecciona el mejor modelo y genera archivo de salida.

```bash
docker-compose run --rm training python experiments/edge_models/select_best_model.py
```

Genera: **`best_edge_model.json`** con toda la informaci√≥n para la siguiente fase.

---

## üìÅ Archivos de Salida

### `best_edge_model.json`

Archivo principal con el modelo seleccionado:

```json
{
  "selection_info": {
    "timestamp": "2025-10-02T16:30:00",
    "total_models_evaluated": 7,
    "models_meeting_requirements": 5,
    "selection_criteria": "Mejor balance precisi√≥n/tama√±o"
  },
  
  "selected_model": {
    "name": "MobileNetV3Small",
    "run_id": "abc123...",
    "artifact_uri": "file:///app/models/mlruns/...",
    "model_file": "MobileNetV3Small_20251002_selected.keras"
  },
  
  "performance_metrics": {
    "test_accuracy": 0.8734,
    "min_recall": 0.8245,
    "recall_per_class": {
      "Blight": 0.8567,
      "Common_Rust": 0.8245,
      "Gray_Leaf_Spot": 0.8923,
      "Healthy": 0.9123
    },
    "meets_minimum_requirements": true
  },
  
  "model_characteristics": {
    "total_parameters": 2534567,
    "model_size_mb": 10.2,
    "efficiency_score": 0.2845,
    "suitable_for_edge": true
  },
  
  "training_configuration": {
    "learning_rate": 0.001,
    "dropout_rate": 0.3,
    "epochs_trained": 30,
    "batch_size": 32,
    "image_size": [224, 224],
    "num_classes": 4,
    "class_names": ["Blight", "Common_Rust", "Gray_Leaf_Spot", "Healthy"]
  },
  
  "all_models_comparison": [...]
}
```

### `comparison_results.csv`

Tabla con todos los modelos y m√©tricas en formato CSV para an√°lisis.

---

## üìä Interpretaci√≥n de Resultados

### Efficiency Score

```
efficiency_score = (accuracy √ó min_recall) / log(size_mb + 1)
```

**Prioriza:**
- Alta precisi√≥n
- Alto recall (cr√≠tico para detecci√≥n de enfermedades)
- Modelo peque√±o

### Cumplimiento de Requisitos

‚úÖ **CUMPLE** si:
- `test_accuracy ‚â• 0.85` (85%)
- `min_recall ‚â• 0.80` (80% en TODAS las clases)

‚ùå **NO CUMPLE** si falla alguno de los requisitos.

---

## üîÑ Workflow Completo

```bash
# 1. Entrenar todos los modelos
docker-compose --profile edge-experiments up

# 2. Comparar resultados
docker-compose run --rm training python experiments/edge_models/compare_models.py

# 3. Seleccionar mejor modelo
docker-compose run --rm training python experiments/edge_models/select_best_model.py

# 4. Ver en MLflow
docker-compose --profile mlflow up -d
open http://localhost:5000
```

---

## üé® Personalizaci√≥n

### Modificar Hiperpar√°metros

Edita `train_all_models.py` en la secci√≥n `EXPERIMENTS`:

```python
EXPERIMENTS = [
    {
        'name': 'MobileNetV3Small',
        'lr': 0.002,          # Cambiar learning rate
        'dropout': 0.4,       # Cambiar dropout
        'epochs': 50,         # M√°s √©pocas
        'fine_tune': True,    # Activar fine-tuning
    },
    # ...
]
```

### Agregar Nuevas Arquitecturas

1. Agregar loader en `src/builders/base_models.py`
2. Actualizar diccionario en `train_edge_model.py`
3. Agregar configuraci√≥n en `train_all_models.py`

---

## üìà Pr√≥ximos Pasos

Una vez seleccionado el mejor modelo (`best_edge_model.json`):

1. **Exportar a TensorFlow Lite**
   ```bash
   # Convertir a .tflite para deployment
   python scripts/convert_to_tflite.py
   ```

2. **Optimizaci√≥n adicional**
   - Quantization (INT8, FP16)
   - Pruning
   - Knowledge distillation

3. **Deployment**
   - Raspberry Pi
   - Jetson Nano
   - Mobile apps (Android/iOS)
   - Microcontroladores

---

**üåΩ ¬°Listo para encontrar el mejor modelo edge!**

