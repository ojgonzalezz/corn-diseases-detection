{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸŒ½ Entrenamiento MobileNetV3 - Corn Diseases Detection\n",
        "\n",
        "**Arquitectura 10/10** - Optimizada para >85% accuracy y >80% recall\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“‹ Pasos:\n",
        "1. âœ… Setup y VerificaciÃ³n\n",
        "2. âœ… ConfiguraciÃ³n y Modelo\n",
        "3. âœ… Entrenamiento Inicial (40 Ã©pocas)\n",
        "4. âœ… Fine-tuning (20 Ã©pocas)\n",
        "5. âœ… EvaluaciÃ³n y Guardado"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ”§ BLOQUE 1: Setup y VerificaciÃ³n"
      ],
      "metadata": {
        "id": "block1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.1 Montar Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 1.2 Clonar repositorio\n",
        "!git clone -b main https://github.com/ojgonzalezz/corn-diseases-detection.git\n",
        "%cd corn-diseases-detection/entrenamiento_modelos\n",
        "\n",
        "# 1.3 Instalar dependencias\n",
        "!pip install -q -r requirements.txt\n",
        "\n",
        "# 1.4 Crear directorios necesarios en Drive\n",
        "!mkdir -p /content/drive/MyDrive/corn-diseases-detection/models\n",
        "!mkdir -p /content/drive/MyDrive/corn-diseases-detection/logs\n",
        "!mkdir -p /content/drive/MyDrive/corn-diseases-detection/mlruns\n",
        "\n",
        "print(\"\\nâœ… Setup completado!\")"
      ],
      "metadata": {
        "id": "setup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ—ï¸ BLOQUE 2: ConfiguraciÃ³n y CreaciÃ³n del Modelo"
      ],
      "metadata": {
        "id": "block2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV3Large\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Importar configuraciÃ³n\n",
        "from config import *\n",
        "from utils import *\n",
        "\n",
        "# Configurar GPU\n",
        "setup_gpu(GPU_MEMORY_LIMIT)\n",
        "\n",
        "# Crear generadores de datos\n",
        "print(\"\\nCreando generadores de datos...\")\n",
        "train_gen, val_gen, test_gen = create_data_generators(\n",
        "    DATA_DIR, IMAGE_SIZE, BATCH_SIZE, TRAIN_SPLIT, VAL_SPLIT, TEST_SPLIT, RANDOM_SEED, DATA_AUGMENTATION\n",
        ")\n",
        "\n",
        "print(f\"\\nðŸ“Š Dataset:\")\n",
        "print(f\"  Training:   {train_gen.samples} imÃ¡genes\")\n",
        "print(f\"  Validation: {val_gen.samples} imÃ¡genes\")\n",
        "print(f\"  Test:       {test_gen.samples} imÃ¡genes\")\n",
        "\n",
        "# Calcular class weights\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(train_gen.classes),\n",
        "    y=train_gen.classes\n",
        ")\n",
        "class_weight_dict = dict(enumerate(class_weights))\n",
        "print(f\"\\nâš–ï¸ Class weights: {class_weight_dict}\")\n",
        "\n",
        "print(\"\\nâœ… ConfiguraciÃ³n completada!\")"
      ],
      "metadata": {
        "id": "config"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear modelo con arquitectura 10/10\n",
        "def create_mobilenetv3_model(num_classes, image_size, learning_rate):\n",
        "    \"\"\"Crear modelo MobileNetV3-Large con arquitectura 10/10\"\"\"\n",
        "    \n",
        "    # Cargar base preentrenada\n",
        "    base_model = MobileNetV3Large(\n",
        "        input_shape=(*image_size, 3),\n",
        "        include_top=False,\n",
        "        weights='imagenet'\n",
        "    )\n",
        "    \n",
        "    # Congelar capas base inicialmente\n",
        "    base_model.trainable = False\n",
        "    \n",
        "    # Arquitectura 10/10: Dense(256) â†’ Dense(128)\n",
        "    inputs = tf.keras.Input(shape=(*image_size, 3))\n",
        "    x = base_model(inputs, training=False)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    \n",
        "    x = Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
        "    x = Dropout(0.35)(x)\n",
        "    \n",
        "    x = Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    \n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "    \n",
        "    model = Model(inputs, outputs)\n",
        "    \n",
        "    # Compilar\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=learning_rate),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Crear modelo\n",
        "print(\"\\nðŸ—ï¸ Creando modelo MobileNetV3-Large...\")\n",
        "model = create_mobilenetv3_model(NUM_CLASSES, IMAGE_SIZE, LEARNING_RATE)\n",
        "print(f\"ðŸ“ Total parÃ¡metros: {model.count_params():,}\")\n",
        "print(\"\\nâœ… Modelo creado!\")"
      ],
      "metadata": {
        "id": "model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸš€ BLOQUE 3: Entrenamiento Inicial (40 Ã©pocas)"
      ],
      "metadata": {
        "id": "block3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Callbacks para entrenamiento inicial\n",
        "callbacks = [\n",
        "    EarlyStopping(\n",
        "        monitor='val_accuracy',\n",
        "        patience=EARLY_STOPPING_PATIENCE,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=REDUCE_LR_PATIENCE,\n",
        "        min_lr=1e-7,\n",
        "        verbose=1\n",
        "    ),\n",
        "    ModelCheckpoint(\n",
        "        str(MODELS_DIR / 'mobilenetv3_best.keras'),\n",
        "        monitor='val_accuracy',\n",
        "        save_best_only=True,\n",
        "        verbose=1\n",
        "    )\n",
        "]\n",
        "\n",
        "print(\"\\nðŸš€ Iniciando entrenamiento inicial...\\n\")\n",
        "start_time = time.time()\n",
        "\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_gen,\n",
        "    callbacks=callbacks,\n",
        "    class_weight=class_weight_dict,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "training_time = time.time() - start_time\n",
        "print(f\"\\nâœ… Entrenamiento completado en {training_time/60:.2f} minutos\")\n",
        "print(f\"ðŸ“Š Mejor Val Accuracy: {max(history.history['val_accuracy']):.4f}\")"
      ],
      "metadata": {
        "id": "training"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸŽ¯ BLOQUE 4: Fine-tuning (20 Ã©pocas)"
      ],
      "metadata": {
        "id": "block4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nðŸŽ¯ Iniciando fine-tuning...\\n\")\n",
        "\n",
        "# Descongelar solo las Ãºltimas 20 capas\n",
        "base_model = model.layers[1]\n",
        "base_model.trainable = True\n",
        "\n",
        "for layer in base_model.layers[:-20]:\n",
        "    layer.trainable = False\n",
        "\n",
        "trainable_layers = sum([1 for layer in base_model.layers if layer.trainable])\n",
        "print(f\"ðŸ”“ Capas descongeladas: {trainable_layers} de {len(base_model.layers)}\\n\")\n",
        "\n",
        "# Recompilar con LR mÃ¡s bajo\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=LEARNING_RATE * 0.05),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Callbacks para fine-tuning\n",
        "finetune_callbacks = [\n",
        "    EarlyStopping(\n",
        "        monitor='val_accuracy',\n",
        "        patience=8,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1,\n",
        "        mode='max'\n",
        "    ),\n",
        "    ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        factor=0.5,\n",
        "        patience=4,\n",
        "        min_lr=1e-7,\n",
        "        verbose=1,\n",
        "        mode='min'\n",
        "    ),\n",
        "    ModelCheckpoint(\n",
        "        str(MODELS_DIR / 'mobilenetv3_best.keras'),\n",
        "        monitor='val_accuracy',\n",
        "        save_best_only=True,\n",
        "        verbose=1,\n",
        "        mode='max'\n",
        "    )\n",
        "]\n",
        "\n",
        "# Fine-tuning\n",
        "history_finetune = model.fit(\n",
        "    train_gen,\n",
        "    epochs=20,\n",
        "    validation_data=val_gen,\n",
        "    callbacks=finetune_callbacks,\n",
        "    class_weight=class_weight_dict,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Combinar historiales\n",
        "for key in history.history:\n",
        "    history.history[key].extend(history_finetune.history[key])\n",
        "\n",
        "finetune_time = time.time() - start_time - training_time\n",
        "total_time = time.time() - start_time\n",
        "\n",
        "print(f\"\\nâœ… Fine-tuning completado en {finetune_time/60:.2f} minutos\")\n",
        "print(f\"â±ï¸ Tiempo total: {total_time/60:.2f} minutos\")"
      ],
      "metadata": {
        "id": "finetuning"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ“Š BLOQUE 5: EvaluaciÃ³n y Guardado de Resultados"
      ],
      "metadata": {
        "id": "block5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"\\nðŸ“Š Evaluando modelo en test set...\\n\")\n",
        "\n",
        "# Evaluar modelo\n",
        "evaluation_results = evaluate_model(model, test_gen, CLASSES)\n",
        "\n",
        "print(f\"\\nâœ… RESULTADOS FINALES:\")\n",
        "print(f\"  Test Accuracy: {evaluation_results['test_accuracy']:.4f} ({evaluation_results['test_accuracy']*100:.2f}%)\")\n",
        "print(f\"  Test Loss:     {evaluation_results['test_loss']:.4f}\")\n",
        "\n",
        "# Mostrar mÃ©tricas por clase\n",
        "print(f\"\\nðŸ“‹ MÃ©tricas por Clase:\")\n",
        "for class_name in CLASSES:\n",
        "    metrics = evaluation_results['classification_report'][class_name]\n",
        "    print(f\"\\n  {class_name}:\")\n",
        "    print(f\"    Precision: {metrics['precision']:.4f}\")\n",
        "    print(f\"    Recall:    {metrics['recall']:.4f}\")\n",
        "    print(f\"    F1-Score:  {metrics['f1-score']:.4f}\")\n",
        "\n",
        "# Guardar grÃ¡ficos\n",
        "plot_path = LOGS_DIR / 'mobilenetv3_training_history.png'\n",
        "plot_training_history(history, plot_path)\n",
        "print(f\"\\nðŸ’¾ GrÃ¡fico guardado: {plot_path}\")\n",
        "\n",
        "# Matriz de confusiÃ³n\n",
        "cm_path = LOGS_DIR / 'mobilenetv3_confusion_matrix.png'\n",
        "cm = plot_confusion_matrix(\n",
        "    evaluation_results['y_true'],\n",
        "    evaluation_results['y_pred'],\n",
        "    CLASSES,\n",
        "    cm_path\n",
        ")\n",
        "print(f\"ðŸ’¾ Matriz de confusiÃ³n guardada: {cm_path}\")\n",
        "\n",
        "# Guardar modelo final\n",
        "model_path = MODELS_DIR / 'mobilenetv3_final.keras'\n",
        "model.save(str(model_path))\n",
        "print(f\"ðŸ’¾ Modelo final guardado: {model_path}\")\n",
        "\n",
        "# Guardar log JSON\n",
        "hyperparameters = {\n",
        "    'model_name': 'MobileNetV3-Large',\n",
        "    'image_size': IMAGE_SIZE,\n",
        "    'batch_size': BATCH_SIZE,\n",
        "    'epochs': EPOCHS,\n",
        "    'learning_rate': LEARNING_RATE,\n",
        "    'architecture': 'Dense(256)->Dense(128) [10/10]'\n",
        "}\n",
        "\n",
        "log_path = LOGS_DIR / 'mobilenetv3_training_log.json'\n",
        "save_training_log(\n",
        "    log_path,\n",
        "    'MobileNetV3-Large',\n",
        "    hyperparameters,\n",
        "    history,\n",
        "    evaluation_results,\n",
        "    cm,\n",
        "    total_time\n",
        ")\n",
        "print(f\"ðŸ’¾ Log guardado: {log_path}\")\n",
        "\n",
        "print(\"\\nðŸŽ‰ Â¡ENTRENAMIENTO COMPLETADO EXITOSAMENTE!\")"
      ],
      "metadata": {
        "id": "evaluation"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
