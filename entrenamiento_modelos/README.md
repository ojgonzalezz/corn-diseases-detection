# Entrenamiento de Modelos - Clasificaci√≥n de Enfermedades del Ma√≠z

Esta carpeta contiene los scripts para entrenar 4 arquitecturas de redes neuronales optimizadas para dispositivos m√≥viles.

## Modelos Implementados

1. **MobileNetV3-Large**: Red neuronal convolucional eficiente de Google
2. **EfficientNet-Lite (B0)**: Arquitectura escalable y eficiente
3. **MobileViT**: Vision Transformer m√≥vil con bloques de atenci√≥n
4. **PMVT**: Plant Mobile Vision Transformer (optimizado para enfermedades de plantas)

## Configuraci√≥n del Dataset

**Divisi√≥n de datos:**
- Entrenamiento: 70% (10,332 im√°genes)
- Validaci√≥n: 15% (2,214 im√°genes)
- Prueba: 15% (2,214 im√°genes)

**Total:** 14,760 im√°genes (3,690 por clase, perfectamente balanceadas)

## Hiperpar√°metros Comunes

```python
IMAGE_SIZE = (256, 256)
BATCH_SIZE = 64
EPOCHS = 20
LEARNING_RATE = 0.001
EARLY_STOPPING_PATIENCE = 10
REDUCE_LR_PATIENCE = 5
```

**Data Augmentation:**
- Rotaci√≥n: ¬±20¬∞
- Desplazamiento horizontal/vertical: ¬±20%
- Flip horizontal y vertical
- Zoom: ¬±20%

## Instalaci√≥n

### Entorno Local

```bash
pip install -r requirements.txt
```

### Google Colab (Recomendado)

**Preparaci√≥n Inicial (una sola vez)**:
1. Habilita GPU: `Runtime` > `Change runtime type` > `Hardware accelerator` > `GPU`
2. Sube `data_processed/` a tu Google Drive en: `Mi unidad/data_processed/`

**üö® DIAGN√ìSTICO ANTES DE EMPEZAR (IMPORTANTE)**:
```python
# Ejecuta este script primero para verificar que todo est√© configurado correctamente
!wget -q https://raw.githubusercontent.com/ojgonzalezz/corn-diseases-detection/pipe/entrenamiento_modelos/diagnostic.py
!python diagnostic.py
```

**Ejecuci√≥n Autom√°tica (Opci√≥n 1 - Recomendada)**:
```python
!wget -q https://raw.githubusercontent.com/ojgonzalezz/corn-diseases-detection/pipe/entrenamiento_modelos/setup_and_train.py
!python setup_and_train.py
```

El script autom√°tico mejorado incluye:
- ‚úì Verificaci√≥n robusta de GPU con timeouts
- ‚úì Montaje de Google Drive con reintentos autom√°ticos
- ‚úì Verificaci√≥n del dataset con espera inteligente
- ‚úì Timeouts en cada paso para evitar cuelgues
- ‚úì Mejor manejo de errores y recuperaci√≥n
- ‚úì Timeout total de 4 horas para todo el proceso

**Ejecuci√≥n Manual (Opci√≥n 2)**:
```python
# 1. Montar Google Drive
from google.colab import drive
drive.mount('/content/drive')

# 2. Clonar repo (rama pipe)
!git clone -b pipe https://github.com/ojgonzalezz/corn-diseases-detection.git
%cd corn-diseases-detection/entrenamiento_modelos

# 3. Instalar dependencias
!pip install -q -r requirements.txt

# 4. Entrenar todos los modelos
!python train_all_models.py
```

Los scripts detectan Colab autom√°ticamente y:
- ‚úì Verifican que GPU est√© habilitada (obligatorio)
- ‚úì Leen dataset desde `Mi unidad/data_processed/`
- ‚úì Guardan modelos en `Mi unidad/corn-diseases-detection/models/`
- ‚úì Guardan logs en `Mi unidad/corn-diseases-detection/logs/`

**Tiempo estimado**: ~40-60 minutos para los 4 modelos con GPU T4
**Nota**: El script mejorado tiene timeouts para evitar cuelgues infinitos

## Uso

### üîß Diagn√≥stico del Entorno

Antes de empezar, verifica que todo est√© configurado correctamente:

```bash
# Script de diagn√≥stico completo
python diagnostic.py

# Solo listar modelos disponibles
python train_single_model.py --list
```

### Entrenar un modelo individual

```bash
# Usando script espec√≠fico
python train_mobilenetv3.py
python train_efficientnet.py
python train_mobilevit.py
python train_pmvt.py

# O usando el script unificado (√∫til para testing)
python train_single_model.py mobilenetv3
python train_single_model.py efficientnet
python train_single_model.py mobilevit
python train_single_model.py pmvt
```

### Entrenar todos los modelos secuencialmente

```bash
# Versi√≥n mejorada con timeouts y mejor manejo de errores
python train_all_models.py
```

**Caracter√≠sticas de la versi√≥n mejorada:**
- ‚è∞ **Timeout por modelo**: 2 horas m√°ximo por modelo
- üîÑ **Contin√∫a si falla**: Si un modelo falla, contin√∫a con el siguiente
- üìä **Resumen detallado**: Genera archivo de resumen al finalizar
- üß† **Liberaci√≥n de memoria**: Pausas entre modelos para liberar GPU

## Salidas Generadas

Para cada modelo se genera:

### Archivos .keras
- `models/{modelo}_best.keras` - Mejor modelo durante entrenamiento
- `models/{modelo}_final.keras` - Modelo final

### Logs
- `logs/{modelo}_training_log.json` - Log detallado en JSON
- `logs/{modelo}_training_log.txt` - Log legible en texto
- `logs/{modelo}_training_history.png` - Gr√°ficos de accuracy y loss
- `logs/{modelo}_confusion_matrix.png` - Matriz de confusi√≥n

### MLflow
- Todos los experimentos se registran autom√°ticamente en MLflow
- Ubicaci√≥n: `mlruns/`

## Visualizar Resultados en MLflow

```bash
cd entrenamiento_modelos
mlflow ui --backend-store-uri mlruns/
```

Luego abrir en navegador: http://localhost:5000

## Estructura de Directorios

```
entrenamiento_modelos/
‚îú‚îÄ‚îÄ config.py                  # Configuraci√≥n com√∫n
‚îú‚îÄ‚îÄ utils.py                   # Utilidades compartidas
‚îú‚îÄ‚îÄ train_mobilenetv3.py      # Entrenamiento MobileNetV3
‚îú‚îÄ‚îÄ train_efficientnet.py     # Entrenamiento EfficientNet
‚îú‚îÄ‚îÄ train_mobilevit.py        # Entrenamiento MobileViT
‚îú‚îÄ‚îÄ train_pmvt.py             # Entrenamiento PMVT
‚îú‚îÄ‚îÄ train_all_models.py       # Entrenar todos
‚îú‚îÄ‚îÄ requirements.txt          # Dependencias
‚îú‚îÄ‚îÄ models/                   # Modelos entrenados (.keras)
‚îú‚îÄ‚îÄ logs/                     # Logs y visualizaciones
‚îî‚îÄ‚îÄ mlruns/                   # Experimentos MLflow
```

## Requisitos del Sistema

**GPU:**
- GPU con soporte CUDA (recomendado)
- Memoria GPU: M√≠nimo 8GB recomendado
- Alternativamente, puede ejecutarse en Google Colab con GPU gratuita

**CPU/RAM:**
- RAM: M√≠nimo 16GB recomendado
- Espacio en disco: ~5GB para modelos y logs

## Informaci√≥n de los Logs

Cada log incluye:
- Hiperpar√°metros utilizados
- M√©tricas de entrenamiento (accuracy, loss)
- M√©tricas de validaci√≥n
- M√©tricas de prueba
- Matriz de confusi√≥n
- Classification report (precision, recall, F1-score)
- Tiempo de entrenamiento

## Comparaci√≥n de Modelos

Despu√©s de entrenar todos los modelos, puedes comparar:

1. **Test Accuracy**: Precisi√≥n en conjunto de prueba
2. **Tiempo de entrenamiento**: Eficiencia computacional
3. **N√∫mero de par√°metros**: Tama√±o del modelo
4. **Matrices de confusi√≥n**: Errores por clase

Usa MLflow UI para comparar m√©tricas lado a lado.

## üîß Soluci√≥n de Problemas

### El script se queda atascado (stuck)

**S√≠ntomas:**
- El script deja de mostrar progreso
- No hay error visible
- Parece "congelado"

**Soluciones:**

1. **Ejecuta el diagn√≥stico primero:**
   ```bash
   python diagnostic.py
   ```
   Esto te dir√° exactamente d√≥nde est√° el problema.

2. **Verifica los puntos comunes de fallo:**
   - ‚ùå **Google Drive no montado**: Ejecuta `from google.colab import drive; drive.mount('/content/drive')`
   - ‚ùå **Dataset no encontrado**: Verifica que `data_processed/` est√© en la ra√≠z de tu Drive
   - ‚ùå **GPU no habilitada**: Ve a `Runtime > Change runtime type > GPU`
   - ‚ùå **Dependencias faltantes**: Ejecuta `pip install -r requirements.txt`

3. **Si el entrenamiento se queda atascado:**
   - Usa `python train_single_model.py mobilenetv3` para probar un modelo individual
   - Los nuevos scripts tienen timeouts de 2 horas por modelo
   - Si un modelo falla, los dem√°s contin√∫an autom√°ticamente

### Errores Comunes

**"No se detect√≥ GPU"**
```bash
# En Google Colab:
# Runtime > Change runtime type > Hardware accelerator > GPU > Save
# Luego reconecta la sesi√≥n
```

**"Dataset no encontrado"**
```
Aseg√∫rate de que la carpeta est√© en:
Mi unidad/data_processed/
  ‚îú‚îÄ‚îÄ Blight/
  ‚îú‚îÄ‚îÄ Common_Rust/
  ‚îú‚îÄ‚îÄ Gray_Leaf_Spot/
  ‚îî‚îÄ‚îÄ Healthy/
```

**"Error de memoria GPU"**
- Reduce `BATCH_SIZE` en `config.py`
- Reinicia la sesi√≥n de Colab
- Usa `GPU_MEMORY_LIMIT = 4096` en config.py

**"Timeout alcanzado"**
- Los nuevos scripts tienen timeouts seguros
- Si un paso toma demasiado tiempo, revisa tu conexi√≥n a internet
- Para Drive lento, el script ahora reintenta autom√°ticamente

### Logs de Depuraci√≥n

Todos los scripts generan logs detallados. Revisa:
- `logs/` - Logs de entrenamiento por modelo
- `entrenamiento_resumen.txt` - Resumen completo
- MLflow UI para m√©tricas detalladas

## Notas Importantes

- Los modelos usan **transfer learning** con pesos de ImageNet
- Se aplica **fine-tuning** despu√©s del entrenamiento inicial (MobileNetV3 y EfficientNet)
- **Early stopping** detiene el entrenamiento si no hay mejora
- **ReduceLROnPlateau** reduce el learning rate autom√°ticamente
- Todos los experimentos son **reproducibles** (RANDOM_SEED=42)

## Pr√≥ximos Pasos

1. Analizar resultados en MLflow
2. Seleccionar el mejor modelo
3. Optimizaci√≥n de hiperpar√°metros del mejor modelo
4. Conversi√≥n a TensorFlow Lite para m√≥viles
5. Despliegue en aplicaci√≥n m√≥vil
