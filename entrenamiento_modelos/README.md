# Entrenamiento de Modelos - Clasificaci√≥n de Enfermedades del Ma√≠z

Esta carpeta contiene los scripts para entrenar 4 arquitecturas de redes neuronales optimizadas para dispositivos m√≥viles.

## Modelos Implementados

1. **MobileNetV3-Large**: Red neuronal convolucional eficiente de Google
2. **EfficientNet-Lite (B0)**: Arquitectura escalable y eficiente
3. **MobileViT**: Vision Transformer m√≥vil con bloques de atenci√≥n
4. **PMVT**: Plant Mobile Vision Transformer (optimizado para enfermedades de plantas)

## Configuraci√≥n del Dataset

**Divisi√≥n de datos:**
- Entrenamiento: 70% (10,332 im√°genes)
- Validaci√≥n: 15% (2,214 im√°genes)
- Prueba: 15% (2,214 im√°genes)

**Total:** 14,760 im√°genes (3,690 por clase, perfectamente balanceadas)

## Hiperpar√°metros Comunes

```python
IMAGE_SIZE = (256, 256)
BATCH_SIZE = 64
EPOCHS = 20
LEARNING_RATE = 0.001
EARLY_STOPPING_PATIENCE = 10
REDUCE_LR_PATIENCE = 5
```

**Data Augmentation:**
- Rotaci√≥n: ¬±20¬∞
- Desplazamiento horizontal/vertical: ¬±20%
- Flip horizontal y vertical
- Zoom: ¬±20%

## Instalaci√≥n

### Entorno Local

```bash
pip install -r requirements.txt
```

### Google Colab (Recomendado)

**Preparaci√≥n Inicial (una sola vez)**:
1. Habilita GPU: `Runtime` > `Change runtime type` > `Hardware accelerator` > `GPU`
2. Sube `data_processed/` a tu Google Drive en: `Mi unidad/data_processed/`

**Ejecuci√≥n en Colab**:
```python
# 1. Montar Google Drive
from google.colab import drive
drive.mount('/content/drive')

# 2. Clonar repo (rama pipe)
!git clone -b pipe https://github.com/ojgonzalezz/corn-diseases-detection.git
%cd corn-diseases-detection/entrenamiento_modelos

# 3. Instalar dependencias
!pip install -q -r requirements.txt

# 4. Entrenar todos los modelos
!python train_all_models.py
```

Los scripts detectan autom√°ticamente el entorno Colab y:
- ‚úì Verifican que GPU est√© habilitada (obligatorio)
- ‚úì Leen dataset desde `Mi unidad/data_processed/`
- ‚úì Guardan modelos en `Mi unidad/corn-diseases-detection/models/`
- ‚úì Guardan logs en `Mi unidad/corn-diseases-detection/logs/`

**Tiempo estimado**: ~40-60 minutos para los 4 modelos con GPU

## Uso

### Entrenar un modelo individual

```bash
# Modelos disponibles
python train_mobilenetv3.py    # MobileNetV3-Large
python train_efficientnet.py   # EfficientNet-Lite
python train_mobilevit.py      # MobileViT
python train_pmvt.py          # PMVT
```

### Entrenar todos los modelos secuencialmente

```bash
python train_all_models.py
```

Ejecuta todos los 4 modelos uno por uno con manejo b√°sico de errores.

## Salidas Generadas

Para cada modelo se genera:

### Archivos .keras
- `models/{modelo}_best.keras` - Mejor modelo durante entrenamiento
- `models/{modelo}_final.keras` - Modelo final

### Logs
- `logs/{modelo}_training_log.json` - Log detallado en JSON
- `logs/{modelo}_training_log.txt` - Log legible en texto
- `logs/{modelo}_training_history.png` - Gr√°ficos de accuracy y loss
- `logs/{modelo}_confusion_matrix.png` - Matriz de confusi√≥n

### MLflow
- Todos los experimentos se registran autom√°ticamente en MLflow
- Ubicaci√≥n: `mlruns/`

## Visualizar Resultados en MLflow

```bash
cd entrenamiento_modelos
mlflow ui --backend-store-uri mlruns/
```

Luego abrir en navegador: http://localhost:5000

## Estructura de Directorios

```
entrenamiento_modelos/
‚îú‚îÄ‚îÄ config.py                  # Configuraci√≥n com√∫n
‚îú‚îÄ‚îÄ utils.py                   # Utilidades compartidas
‚îú‚îÄ‚îÄ train_mobilenetv3.py      # Entrenamiento MobileNetV3
‚îú‚îÄ‚îÄ train_efficientnet.py     # Entrenamiento EfficientNet
‚îú‚îÄ‚îÄ train_mobilevit.py        # Entrenamiento MobileViT
‚îú‚îÄ‚îÄ train_pmvt.py             # Entrenamiento PMVT
‚îú‚îÄ‚îÄ train_all_models.py       # Script para entrenar todos los modelos
‚îú‚îÄ‚îÄ requirements.txt          # Dependencias Python
‚îú‚îÄ‚îÄ README.md                 # Esta documentaci√≥n
‚îú‚îÄ‚îÄ models/                   # Modelos entrenados (.keras)
‚îú‚îÄ‚îÄ logs/                     # Logs y visualizaciones
‚îî‚îÄ‚îÄ mlruns/                   # Experimentos MLflow
```

## Requisitos del Sistema

**GPU:**
- GPU con soporte CUDA (recomendado)
- Memoria GPU: M√≠nimo 8GB recomendado
- Alternativamente, puede ejecutarse en Google Colab con GPU gratuita

**CPU/RAM:**
- RAM: M√≠nimo 16GB recomendado
- Espacio en disco: ~5GB para modelos y logs

## Informaci√≥n de los Logs

Cada log incluye:
- Hiperpar√°metros utilizados
- M√©tricas de entrenamiento (accuracy, loss)
- M√©tricas de validaci√≥n
- M√©tricas de prueba
- Matriz de confusi√≥n
- Classification report (precision, recall, F1-score)
- Tiempo de entrenamiento

## Comparaci√≥n de Modelos

Despu√©s de entrenar todos los modelos, puedes comparar:

1. **Test Accuracy**: Precisi√≥n en conjunto de prueba
2. **Tiempo de entrenamiento**: Eficiencia computacional
3. **N√∫mero de par√°metros**: Tama√±o del modelo
4. **Matrices de confusi√≥n**: Errores por clase

Usa MLflow UI para comparar m√©tricas lado a lado.

## üîß Soluci√≥n de Problemas

### El script se queda atascado (stuck)

**S√≠ntomas:**
- El script deja de mostrar progreso
- No hay error visible
- Parece "congelado"

**Soluciones:**

1. **Ejecuta el diagn√≥stico primero:**
   ```bash
   python diagnostic.py
   ```
   Esto te dir√° exactamente d√≥nde est√° el problema.

2. **Verifica los puntos comunes de fallo:**
   - ‚ùå **Google Drive no montado**: Ejecuta `from google.colab import drive; drive.mount('/content/drive')`
   - ‚ùå **Dataset no encontrado**: Verifica que `data_processed/` est√© en la ra√≠z de tu Drive
   - ‚ùå **GPU no habilitada**: Ve a `Runtime > Change runtime type > GPU`
   - ‚ùå **Dependencias faltantes**: Ejecuta `pip install -r requirements.txt`

3. **Si el entrenamiento se queda atascado:**
   - Usa `python train_single_model.py mobilenetv3` para probar un modelo individual
   - Los nuevos scripts tienen timeouts de 2 horas por modelo
   - Si un modelo falla, los dem√°s contin√∫an autom√°ticamente

### Errores Comunes

**"No se detect√≥ GPU"**
```bash
# En Google Colab:
# Runtime > Change runtime type > Hardware accelerator > GPU > Save
# Luego reconecta la sesi√≥n
```

**"Dataset no encontrado"**
```
Aseg√∫rate de que la carpeta est√© en:
Mi unidad/data_processed/
  ‚îú‚îÄ‚îÄ Blight/
  ‚îú‚îÄ‚îÄ Common_Rust/
  ‚îú‚îÄ‚îÄ Gray_Leaf_Spot/
  ‚îî‚îÄ‚îÄ Healthy/
```

**"Error de memoria GPU"**
- Reduce `BATCH_SIZE` en `config.py`
- Reinicia la sesi√≥n de Colab
- Usa `GPU_MEMORY_LIMIT = 4096` en config.py

**"Timeout alcanzado"**
- Los nuevos scripts tienen timeouts seguros
- Si un paso toma demasiado tiempo, revisa tu conexi√≥n a internet
- Para Drive lento, el script ahora reintenta autom√°ticamente

### Logs de Depuraci√≥n

Todos los scripts generan logs detallados. Revisa:
- `logs/` - Logs de entrenamiento por modelo
- `entrenamiento_resumen.txt` - Resumen completo
- MLflow UI para m√©tricas detalladas

## Notas Importantes

- Los modelos usan **transfer learning** con pesos de ImageNet
- Se aplica **fine-tuning** despu√©s del entrenamiento inicial (MobileNetV3 y EfficientNet)
- **Early stopping** detiene el entrenamiento si no hay mejora
- **ReduceLROnPlateau** reduce el learning rate autom√°ticamente
- Todos los experimentos son **reproducibles** (RANDOM_SEED=42)

## Pr√≥ximos Pasos

1. Analizar resultados en MLflow
2. Seleccionar el mejor modelo
3. Optimizaci√≥n de hiperpar√°metros del mejor modelo
4. Conversi√≥n a TensorFlow Lite para m√≥viles
5. Despliegue en aplicaci√≥n m√≥vil
