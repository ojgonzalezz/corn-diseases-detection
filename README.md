
-----

# ğŸŒ½ Corn Diseases Detection with Transfer Learning
# ğŸŒ½ DetecciÃ³n de Enfermedades del MaÃ­z con Transfer Learning

> **Note:** This project contains documentation in both English and Spanish to support international collaboration.
> **Nota:** Este proyecto contiene documentaciÃ³n en inglÃ©s y espaÃ±ol para apoyar la colaboraciÃ³n internacional.

---

## ğŸŒŸ Project Summary | Resumen del Proyecto

**[EN]** This project implements a robust **Deep Learning pipeline** for classifying common corn leaf diseases. Using **Transfer Learning** with VGG16, **Keras Tuner** for hyperparameter optimization, and **MLflow** for experiment tracking, the system achieves high accuracy in diagnosing plant health. The project emphasizes rigorous preprocessing to address **data leakage** and **class imbalance** in a multi-source dataset.

**Key Features:**
- ğŸ§  Transfer Learning with VGG16/ResNet50
- ğŸ” Intelligent de-augmentation using ResNet50 embeddings
- âš–ï¸ Advanced class balancing (oversample/downsample)
- ğŸ“Š MLflow experiment tracking
- ğŸ¯ Keras Tuner hyperparameter optimization

---

**[ES]** Este proyecto implementa un *pipeline* de *Deep Learning* robusto para la **clasificaciÃ³n de enfermedades comunes en hojas de maÃ­z**. El objetivo es diagnosticar automÃ¡ticamente la salud de las plantas utilizando tÃ©cnicas de *Transfer Learning* basadas en la arquitectura VGG16, optimizando la cabeza de clasificaciÃ³n mediante **Keras Tuner** y rastreando todos los experimentos con **MLflow**. El proyecto se destaca por su rigurosa estrategia de preprocesamiento, que aborda activamente el **sesgo por duplicaciÃ³n (data leakage)** y el **desbalance de clases** en un *dataset* bimodal compuesto por dos fuentes de datos distintas.

-----

ğŸ“œ Problema y Contexto
Las enfermedades del maÃ­z, como la roya comÃºn, el tizÃ³n foliar y la mancha gris, representan una amenaza crÃ­tica para la seguridad alimentaria. El diagnÃ³stico tradicional mediante inspecciÃ³n visual es un proceso lento, subjetivo y dependiente de la pericia del observador. Este proyecto busca validar la viabilidad de un sistema de diagnÃ³stico automatizado mediante Inteligencia Artificial para superar estas limitaciones.

-----

## ğŸ¯ Objetivo y Tipos de Datos

### Objetivo Principal

Desarrollar un modelo de clasificaciÃ³n de imÃ¡genes altamente preciso y generalizable, capaz de diferenciar entre las siguientes cuatro categorÃ­as de salud de las hojas de maÃ­z:

1.  **Blight**
2.  **Common\_Rust**
3.  **Gray\_Leaf\_Spot**
4.  **Healthy**

### Tipos de Datos

El *dataset* estÃ¡ compuesto por imÃ¡genes RGB de hojas de maÃ­z, recopiladas de dos fuentes distintas que se manejan por separado para controlar el *Data Augmentation*:

| Fuente | DescripciÃ³n | ConsideraciÃ³n |
| :--- | :--- | :--- |
| **`data_1`** | Dataset primario (ej., Kaggle). | **No-Augmentation** (Se considera limpio y original). |
| **`data_2`** | Dataset secundario (ej., Roboflow). | **Augmented** (Contiene *Data Augmentation* preaplicado, introduciendo riesgo de sesgo). |

-----

## ğŸ› ï¸ Retos de Datos y Pipeline de Preprocesamiento

El mayor desafÃ­o del proyecto fue mitigar el **sesgo por duplicaciÃ³n** presente en la fuente `data_2`, lo que habrÃ­a inflado artificialmente las mÃ©tricas de prueba. Para garantizar la integridad del modelo, se estableciÃ³ un *pipeline* de tres fases:

### 1\. DesafÃ­o: Sesgo por DuplicaciÃ³n (*Data Leakage*)

El sesgo por duplicaciÃ³n ocurre cuando una misma imagen o una copia casi idÃ©ntica (resultado de un *Data Augmentation* simple) se encuentra tanto en el conjunto de entrenamiento como en el de prueba, lo que conduce al **sobreajuste** (el modelo memoriza en lugar de generalizar).

### Estrategia de De-AugmentaciÃ³n por Embedding

Para contrarrestar esto, se aplicÃ³ una estrategia innovadora de filtrado antes de la divisiÃ³n de datos:

  * **GeneraciÃ³n de Embeddings:** Se generaron vectores de caracterÃ­sticas (*embeddings*) para todas las imÃ¡genes en la fuente `"augmented"` (`data_2`) utilizando un modelo preentrenado (ej., la base VGG16).
  * **Similitud del Coseno ($\cos(\theta)$):** Se calculÃ³ la similitud del coseno entre todos los pares de *embeddings* dentro de cada categorÃ­a. Las imÃ¡genes con una similitud superior a un umbral alto ($\tau \ge 0.95$) fueron identificadas como duplicados artificiales.
  * **Filtrado:** El *pipeline* eliminÃ³ una de las imÃ¡genes del par similar, asegurando que solo **una versiÃ³n representativa** de cada imagen original se conservara en el conjunto de datos final.

### 2\. DivisiÃ³n Estratificada y Balanceo de Clases

Una vez filtrados los duplicados, las imÃ¡genes de `data_1` y las filtradas de `data_2` se unificaron y se procesaron para la fase de entrenamiento:

  * **UnificaciÃ³n y DivisiÃ³n Estratificada:** El conjunto de datos unificado se dividiÃ³ en `Train`, `Validation` y `Test` utilizando la funciÃ³n **`stratified_split_dataset`**. Esta divisiÃ³n garantiza que la proporciÃ³n de cada clase de enfermedad sea la misma en los tres conjuntos, lo cual es fundamental para una evaluaciÃ³n imparcial.
  * **Balanceo (Solo en el set de Train):** Para corregir el desbalance, solo se modifica el conjunto de entrenamiento, evitando la contaminaciÃ³n de los sets de validaciÃ³n y prueba.
      * **Modo Downsampling:** Reduce el nÃºmero de imÃ¡genes de todas las clases al tamaÃ±o de la clase minoritaria.
      * **Modo Oversampling:** Expande las clases minoritarias hasta un tamaÃ±o objetivo (clase mayoritaria + N extra) utilizando una estrategia de **aumento en cascada** (doble transformaciÃ³n de calidad seguida de una transformaciÃ³n espacial) para generar variaciones mÃ¡s robustas.

-----

## ğŸ§  MetodologÃ­a General de Entrenamiento (MÃ©tricas y OptimizaciÃ³n)

El proyecto emplea una metodologÃ­a rigurosa para el entrenamiento y el seguimiento de los experimentos:

1.  **Transfer Learning:** Se utiliza el modelo **VGG16** preentrenado en ImageNet como *backbone*, congelando sus capas convolucionales para aprovechar las caracterÃ­sticas visuales aprendidas.
2.  **BÃºsqueda de HiperparÃ¡metros (Keras Tuner):** Se utiliza la tÃ©cnica **Hyperband** de Keras Tuner para encontrar la arquitectura Ã³ptima para la cabeza de clasificaciÃ³n (las capas densas) que se aÃ±ade al *backbone* de VGG16.
3.  **Seguimiento de Experimentos (MLflow):** Todos los *trials* generados por Keras Tuner son registrados como *runs* individuales en MLflow. Esto incluye:
      * Registro de hiperparÃ¡metros por *trial*.
      * Registro de mÃ©tricas por Ã©poca (`loss`, `accuracy`, `val_loss`, `val_accuracy`).
      * Guardado del modelo final (`best_model.h5`) y las mÃ©tricas de rendimiento en el conjunto de prueba.

-----

## ğŸ“‚ Estructura Detallada del Repositorio

El proyecto sigue una estructura modular y escalable para separar el cÃ³digo de producciÃ³n (`src`), los datos (`data`), y la experimentaciÃ³n (`notebooks`).

```
corn-diseases-detection/
â”œâ”€â”€ data/                     # Dataset directory (gitignored)
â”‚   â”œâ”€â”€ train/                # Training set (3,856 images - balanced)
â”‚   â”‚   â”œâ”€â”€ Blight/           # 964 images
â”‚   â”‚   â”œâ”€â”€ Common_Rust/      # 964 images
â”‚   â”‚   â”œâ”€â”€ Gray_Leaf_Spot/   # 964 images
â”‚   â”‚   â””â”€â”€ Healthy/          # 964 images
â”‚   â”œâ”€â”€ val/                  # Validation set (716 images - stratified)
â”‚   â”‚   â”œâ”€â”€ Blight/           # 171 images
â”‚   â”‚   â”œâ”€â”€ Common_Rust/      # 195 images
â”‚   â”‚   â”œâ”€â”€ Gray_Leaf_Spot/   # 176 images
â”‚   â”‚   â””â”€â”€ Healthy/          # 174 images
â”‚   â””â”€â”€ test/                 # Test set (722 images - stratified)
â”‚       â”œâ”€â”€ Blight/           # 173 images
â”‚       â”œâ”€â”€ Common_Rust/      # 197 images
â”‚       â”œâ”€â”€ Gray_Leaf_Spot/   # 177 images
â”‚       â””â”€â”€ Healthy/          # 175 images
â”‚
â”œâ”€â”€ experimentation/          # EDA and exploration scripts
â”‚   â”œâ”€â”€ eda/                  # Data validation and analysis
â”‚   â”‚   â”œâ”€â”€ analyze_feature.py
â”‚   â”‚   â”œâ”€â”€ explore_distribution.py
â”‚   â”‚   â”œâ”€â”€ validate_dataset.py
â”‚   â”‚   â””â”€â”€ view_samples.py
â”‚   â””â”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda_exploracion.ipynb 
â”‚   â”œâ”€â”€ 02_modelado_basico.ipynb
â”‚   â””â”€â”€ 03_transfer_learning.ipynb
â”‚
â”œâ”€â”€ models/                   # Model artifacts (gitignored)
â”‚   â”œâ”€â”€ mlruns/               # MLflow experiment tracking
â”‚   â”œâ”€â”€ tuner_checkpoints/    # Keras Tuner hyperparameter search
â”‚   â””â”€â”€ exported/             # Final trained models (best_VGG16.keras, etc.)
â”‚
â”œâ”€â”€ src/                      # CÃ³digo fuente de producciÃ³n
â”‚   â”œâ”€â”€ adapters/
â”‚   â”‚   â””â”€â”€ data_loader.py    # AbstracciÃ³n: Carga de datos de mÃºltiples fuentes
â”‚   â”œâ”€â”€ builders/
â”‚   â”‚   â”œâ”€â”€ base_models.py    # DefiniciÃ³n de backbones preentrenados (VGG16)
â”‚   â”‚   â””â”€â”€ builders.py       # Ensamblaje de la cabeza de clasificaciÃ³n para Keras Tuner
â”‚   â”œâ”€â”€ core/                 # ConfiguraciÃ³n y utilidades de entorno
â”‚   â”‚   â”œâ”€â”€ load_env.py       # Carga de variables de entorno (.env)
â”‚   â”‚   â””â”€â”€ path_finder.py    # DetecciÃ³n de la ruta raÃ­z del proyecto
â”‚   â”œâ”€â”€ pipelines/            # Scripts del ciclo de Machine Learning
â”‚   â”‚   â”œâ”€â”€ data_pipeline.py  # GeneraciÃ³n de DataGenerators para Keras
â”‚   â”‚   â”œâ”€â”€ evaluate_finetuned.py
â”‚   â”‚   â”œâ”€â”€ train.py          # OrquestaciÃ³n del entrenamiento con Keras Tuner/MLflow
â”‚   â”‚   â”œâ”€â”€ preproces.py      # Script principal de filtrado, unificaciÃ³n y balanceo (Down/Oversampling)
â”‚   â”‚   â””â”€â”€ infer.py          # LÃ³gica de inferencia para la API (clasificaciÃ³n)
â”‚   â””â”€â”€ utils/                # Funciones de ayuda
â”‚       â”œâ”€â”€ aug_detectors.py    # DetecciÃ³n y filtrado de aumentaciones por Embedding
â”‚       â”œâ”€â”€ data_augmentator.py # Transformaciones espaciales para Oversampling
â”‚       â”œâ”€â”€ image_modifier.py   # Transformaciones de calidad (brillo, contraste, ruido)
â”‚       â””â”€â”€ utils.py          # Utilidades miscelÃ¡neas
â”‚
â”œâ”€â”€ reports/                  # DocumentaciÃ³n y resultados
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

### ğŸ“Š Data Workflow Note

**Current Structure:** The project uses pre-split data in `data/train/`, `data/val/`, `data/test/` directories. This is the actual working structure.

**Why this structure?** The data has already been preprocessed, balanced, and split using the preprocessing pipeline in `src/pipelines/preprocess.py`. The split is:
- **Training:** 70% (3,856 images - perfectly balanced across 4 classes)
- **Validation:** 15% (716 images - stratified)
- **Testing:** 15% (722 images - stratified)

### DescripciÃ³n Profesional de MÃ³dulos y Scripts

| Carpeta/Script | DescripciÃ³n |
| :--- | :--- |
| **`data/train/`** | Training dataset with balanced classes (964 images per class) |
| **`data/val/`** | Validation dataset with stratified split for model evaluation |
| **`data/test/`** | Test dataset for final model assessment |
| **`experimentation/`** | EDA scripts and Jupyter notebooks for exploration |
| **`models/exported/`** | Final trained models ready for inference (e.g., `best_VGG16.keras`) |
| **`src/adapters/data_loader.py`** | Componente de abstracciÃ³n de datos. Encargado de cargar las imÃ¡genes desde el disco a memoria (`PIL.Image`) desde mÃºltiples fuentes (`data_1`, `data_2`). |
| **`src/builders/builders.py`** | FactorÃ­a de modelos. Define la arquitectura de la cabeza de clasificaciÃ³n y ensambla el modelo completo (VGG16 + cabeza), listo para la bÃºsqueda de hiperparÃ¡metros con Keras Tuner. |
| **`src/core/load_env.py`** | Utilidad de configuraciÃ³n. Carga y parsea de forma segura todas las variables de entorno (rutas, ratios, tamaÃ±os de imagen) desde el archivo `.env`. |
| **`src/pipelines/train.py`** | Script de orquestaciÃ³n central. Ejecuta la bÃºsqueda de Keras Tuner, aplica *Early Stopping* y registra todos los resultados en MLflow. |
| **`src/pipelines/preprocess.py`** | Script principal del *pipeline* de datos. Dirige el filtrado, la unificaciÃ³n, la divisiÃ³n estratificada y el balanceo (submuestreo/sobremuestreo) de los datos. |
| **`src/pipelines/infer.py`** | Pipeline de inferencia optimizado para el servidor. Carga el modelo final y contiene la funciÃ³n **`predict()`** utilizada por la API para clasificar imÃ¡genes. |
| **`src/utils/aug_detectors.py`** | Implementa la lÃ³gica de **De-AugmentaciÃ³n**; contiene las funciones para la generaciÃ³n de *embeddings* y el cÃ¡lculo de la similitud del coseno para detectar duplicados. |
| **`src/utils/data_augmentator.py`** | Define las funciones para las transformaciones espaciales complejas utilizadas durante el *oversampling* controlado. |
| **`src/utils/image_modifier.py`** | Contiene funciones de bajo nivel para las transformaciones de *calidad* de imagen (ej., ruido, brillo, contraste) utilizadas en el *Data Augmentation*. |

---

## ğŸš€ Quick Start | Inicio RÃ¡pido

### Installation | InstalaciÃ³n

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Training | Entrenamiento

```bash
# Train model with default settings (VGG16, balanced data)
python -m src.pipelines.train

# Train with specific backbone
python -c "from src.pipelines.train import train; train(backbone_name='ResNet50')"
```

### Inference | Inferencia

```python
from src.pipelines.infer import predict

# Load image as bytes
with open('path/to/corn_leaf.jpg', 'rb') as f:
    image_bytes = f.read()

# Get prediction
result = predict(image_bytes)
print(f"Predicted: {result['predicted_label']}")
print(f"Confidence: {result['confidence']:.2%}")
```

### Configuration | ConfiguraciÃ³n

Edit `src/core/.env` to customize:
- `IMAGE_SIZE`: Input image dimensions
- `NUM_CLASSES`: Number of disease classes
- `BATCH_SIZE`: Training batch size
- `MAX_TRIALS`: Keras Tuner search iterations

---

## ğŸ§ª Testing Strategy | Estrategia de Pruebas

**[EN] Current Status:** The project currently uses EDA scripts in `experimentation/eda/` for data validation:
- `validate_dataset.py`: Checks image integrity and counts by class
- `explore_distribution.py`: Analyzes class distributions
- `view_samples.py`: Visual inspection of samples

**Recommended Testing Approach:**
```bash
# Validate dataset integrity
python experimentation/eda/validate_dataset.py

# Check class distributions
python experimentation/eda/explore_distribution.py
```

**Future Improvements:**
- Add `tests/` directory with pytest
- Unit tests for preprocessing functions
- Integration tests for training pipeline
- Model performance regression tests

**[ES] Estado Actual:** El proyecto utiliza scripts EDA en `experimentation/eda/` para validaciÃ³n de datos. Se recomienda agregar pruebas unitarias con pytest en el futuro.

---

## ğŸ“¦ Model Versioning | Versionado de Modelos

**[EN] Automated Versioning:** The training pipeline automatically saves models with version information:

**File Naming Convention:**
```
models/exported/
â”œâ”€â”€ VGG16_20250102_143022_acc0.9745.keras    # Timestamped + accuracy
â”œâ”€â”€ VGG16_20250102_143022_metadata.json      # Training configuration
â””â”€â”€ best_VGG16.keras                         # Latest best model (for inference)
```

**Metadata Includes:**
- Timestamp
- Test accuracy and loss
- Hyperparameters used
- Data split ratios
- Balancing strategy
- Image size and number of classes

**Model Registry:** All training runs are tracked in MLflow at `models/mlruns/` for experiment comparison.

**[ES] Versionado AutomÃ¡tico:** El pipeline guarda modelos con timestamp, precisiÃ³n y metadatos en JSON. MLflow rastrea todos los experimentos.

---
