
-----

# ğŸŒ½ DetecciÃ³n de Enfermedades del MaÃ­z con Transfer Learning

## ğŸŒŸ Resumen del Proyecto

Este proyecto implementa un *pipeline* de *Deep Learning* robusto para la **clasificaciÃ³n de enfermedades comunes en hojas de maÃ­z**. El objetivo es diagnosticar automÃ¡ticamente la salud de las plantas utilizando tÃ©cnicas de *Transfer Learning* basadas en la arquitectura VGG16, optimizando la cabeza de clasificaciÃ³n mediante **Keras Tuner** y rastreando todos los experimentos con **MLflow**.

El proyecto se destaca por su rigurosa estrategia de preprocesamiento, que aborda activamente el **sesgo por duplicaciÃ³n (data leakage)** y el **desbalance de clases** en un *dataset* bimodal compuesto por dos fuentes de datos distintas.

-----

ğŸ“œ Problema y Contexto
Las enfermedades del maÃ­z, como la roya comÃºn, el tizÃ³n foliar y la mancha gris, representan una amenaza crÃ­tica para la seguridad alimentaria. El diagnÃ³stico tradicional mediante inspecciÃ³n visual es un proceso lento, subjetivo y dependiente de la pericia del observador. Este proyecto busca validar la viabilidad de un sistema de diagnÃ³stico automatizado mediante Inteligencia Artificial para superar estas limitaciones.

-----

## ğŸ¯ Objetivo y Tipos de Datos

### Objetivo Principal

Desarrollar un modelo de clasificaciÃ³n de imÃ¡genes altamente preciso y generalizable, capaz de diferenciar entre las siguientes cuatro categorÃ­as de salud de las hojas de maÃ­z:

1.  **Blight**
2.  **Common\_Rust**
3.  **Gray\_Leaf\_Spot**
4.  **Healthy**

### Tipos de Datos

El *dataset* estÃ¡ compuesto por imÃ¡genes RGB de hojas de maÃ­z, recopiladas de dos fuentes distintas que se manejan por separado para controlar el *Data Augmentation*:

| Fuente | DescripciÃ³n | ConsideraciÃ³n |
| :--- | :--- | :--- |
| **`data_1`** | Dataset primario (ej., Kaggle). | **No-Augmentation** (Se considera limpio y original). |
| **`data_2`** | Dataset secundario (ej., Roboflow). | **Augmented** (Contiene *Data Augmentation* preaplicado, introduciendo riesgo de sesgo). |

-----

## ğŸ› ï¸ Retos de Datos y Pipeline de Preprocesamiento

El mayor desafÃ­o del proyecto fue mitigar el **sesgo por duplicaciÃ³n** presente en la fuente `data_2`, lo que habrÃ­a inflado artificialmente las mÃ©tricas de prueba. Para garantizar la integridad del modelo, se estableciÃ³ un *pipeline* de tres fases:

### 1\. DesafÃ­o: Sesgo por DuplicaciÃ³n (*Data Leakage*)

El sesgo por duplicaciÃ³n ocurre cuando una misma imagen o una copia casi idÃ©ntica (resultado de un *Data Augmentation* simple) se encuentra tanto en el conjunto de entrenamiento como en el de prueba, lo que conduce al **sobreajuste** (el modelo memoriza en lugar de generalizar).

### Estrategia de De-AugmentaciÃ³n por Embedding

Para contrarrestar esto, se aplicÃ³ una estrategia innovadora de filtrado antes de la divisiÃ³n de datos:

  * **GeneraciÃ³n de Embeddings:** Se generaron vectores de caracterÃ­sticas (*embeddings*) para todas las imÃ¡genes en la fuente `"augmented"` (`data_2`) utilizando un modelo preentrenado (ej., la base VGG16).
  * **Similitud del Coseno ($\cos(\theta)$):** Se calculÃ³ la similitud del coseno entre todos los pares de *embeddings* dentro de cada categorÃ­a. Las imÃ¡genes con una similitud superior a un umbral alto ($\tau \ge 0.95$) fueron identificadas como duplicados artificiales.
  * **Filtrado:** El *pipeline* eliminÃ³ una de las imÃ¡genes del par similar, asegurando que solo **una versiÃ³n representativa** de cada imagen original se conservara en el conjunto de datos final.

### 2\. DivisiÃ³n Estratificada y Balanceo de Clases

Una vez filtrados los duplicados, las imÃ¡genes de `data_1` y las filtradas de `data_2` se unificaron y se procesaron para la fase de entrenamiento:

  * **UnificaciÃ³n y DivisiÃ³n Estratificada:** El conjunto de datos unificado se dividiÃ³ en `Train`, `Validation` y `Test` utilizando la funciÃ³n **`stratified_split_dataset`**. Esta divisiÃ³n garantiza que la proporciÃ³n de cada clase de enfermedad sea la misma en los tres conjuntos, lo cual es fundamental para una evaluaciÃ³n imparcial.
  * **Balanceo (Solo en el set de Train):** Para corregir el desbalance, solo se modifica el conjunto de entrenamiento, evitando la contaminaciÃ³n de los sets de validaciÃ³n y prueba.
      * **Modo Downsampling:** Reduce el nÃºmero de imÃ¡genes de todas las clases al tamaÃ±o de la clase minoritaria.
      * **Modo Oversampling:** Expande las clases minoritarias hasta un tamaÃ±o objetivo (clase mayoritaria + N extra) utilizando una estrategia de **aumento en cascada** (doble transformaciÃ³n de calidad seguida de una transformaciÃ³n espacial) para generar variaciones mÃ¡s robustas.

-----

## ğŸ§  MetodologÃ­a General de Entrenamiento (MÃ©tricas y OptimizaciÃ³n)

El proyecto emplea una metodologÃ­a rigurosa para el entrenamiento y el seguimiento de los experimentos:

1.  **Transfer Learning:** Se utiliza el modelo **VGG16** preentrenado en ImageNet como *backbone*, congelando sus capas convolucionales para aprovechar las caracterÃ­sticas visuales aprendidas.
2.  **BÃºsqueda de HiperparÃ¡metros (Keras Tuner):** Se utiliza la tÃ©cnica **Hyperband** de Keras Tuner para encontrar la arquitectura Ã³ptima para la cabeza de clasificaciÃ³n (las capas densas) que se aÃ±ade al *backbone* de VGG16.
3.  **Seguimiento de Experimentos (MLflow):** Todos los *trials* generados por Keras Tuner son registrados como *runs* individuales en MLflow. Esto incluye:
      * Registro de hiperparÃ¡metros por *trial*.
      * Registro de mÃ©tricas por Ã©poca (`loss`, `accuracy`, `val_loss`, `val_accuracy`).
      * Guardado del modelo final (`best_model.h5`) y las mÃ©tricas de rendimiento en el conjunto de prueba.

-----

## ğŸ“‚ Estructura Detallada del Repositorio

El proyecto sigue una estructura modular y escalable para separar el cÃ³digo de producciÃ³n (`src`), los datos (`data`), y la experimentaciÃ³n (`notebooks`).

```
corn-diseases-detection/
mi_proyecto_maiz_dl/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                  # Datos originales (no modificados)
â”‚   â”‚   â”œâ”€â”€ train/            # Dataset de entrenamiento original
â”‚   â”‚   â””â”€â”€ validation/       # Dataset de validaciÃ³n original
â”‚   â””â”€â”€ processed/            # Datos limpios y listos para el ciclo ML
â”‚       â”œâ”€â”€ data_1            # Fuente 1 (limpia/no-augmentada)
â”‚       â”œâ”€â”€ data_2            # Fuente 2 (des-aumentada/filtrada)
â”‚       â””â”€â”€ split             # Conjuntos finales para el modelo
â”‚           â”œâ”€â”€ train/        # Conjunto de Entrenamiento (balanceado)
â”‚           â”œâ”€â”€ val/          # Conjunto de ValidaciÃ³n (estratificado)
â”‚           â””â”€â”€ test/         # Conjunto de Prueba (estratificado)
â”‚
â”œâ”€â”€ notebooks/                # Espacio para experimentaciÃ³n y EDA
â”‚   â”œâ”€â”€ 01_eda_exploracion.ipynb 
â”‚   â”œâ”€â”€ 02_modelado_basico.ipynb
â”‚   â””â”€â”€ 03_transfer_learning.ipynb
â”‚
â”œâ”€â”€ models/                   # Artefactos de modelos
â”‚   â”œâ”€â”€ checkpoints/          # Puntos de control intermedios (MLflow)
â”‚   â””â”€â”€ exported/             # Versiones finales para inferencia/producciÃ³n
â”‚
â”œâ”€â”€ src/                      # CÃ³digo fuente de producciÃ³n
â”‚   â”œâ”€â”€ adapters/
â”‚   â”‚   â””â”€â”€ data_loader.py    # AbstracciÃ³n: Carga de datos de mÃºltiples fuentes
â”‚   â”œâ”€â”€ builders/
â”‚   â”‚   â”œâ”€â”€ base_models.py    # DefiniciÃ³n de backbones preentrenados (VGG16)
â”‚   â”‚   â””â”€â”€ builders.py       # Ensamblaje de la cabeza de clasificaciÃ³n para Keras Tuner
â”‚   â”œâ”€â”€ core/                 # ConfiguraciÃ³n y utilidades de entorno
â”‚   â”‚   â”œâ”€â”€ load_env.py       # Carga de variables de entorno (.env)
â”‚   â”‚   â””â”€â”€ path_finder.py    # DetecciÃ³n de la ruta raÃ­z del proyecto
â”‚   â”œâ”€â”€ pipelines/            # Scripts del ciclo de Machine Learning
â”‚   â”‚   â”œâ”€â”€ data_pipeline.py  # GeneraciÃ³n de DataGenerators para Keras
â”‚   â”‚   â”œâ”€â”€ evaluate_finetuned.py
â”‚   â”‚   â”œâ”€â”€ train.py          # OrquestaciÃ³n del entrenamiento con Keras Tuner/MLflow
â”‚   â”‚   â”œâ”€â”€ preproces.py      # Script principal de filtrado, unificaciÃ³n y balanceo (Down/Oversampling)
â”‚   â”‚   â””â”€â”€ infer.py          # LÃ³gica de inferencia para la API (clasificaciÃ³n)
â”‚   â””â”€â”€ utils/                # Funciones de ayuda
â”‚       â”œâ”€â”€ aug_detectors.py    # DetecciÃ³n y filtrado de aumentaciones por Embedding
â”‚       â”œâ”€â”€ data_augmentator.py # Transformaciones espaciales para Oversampling
â”‚       â”œâ”€â”€ image_modifier.py   # Transformaciones de calidad (brillo, contraste, ruido)
â”‚       â””â”€â”€ utils.py          # Utilidades miscelÃ¡neas
â”‚
â”œâ”€â”€ reports/                  # DocumentaciÃ³n y resultados
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

### DescripciÃ³n Profesional de MÃ³dulos y Scripts

| Carpeta/Script | DescripciÃ³n |
| :--- | :--- |
| **`data/raw/`** | Contiene los datasets originales. Estos archivos nunca deben ser modificados por el cÃ³digo. |
| **`data/processed/`** | Almacena los datasets limpios, filtrados y listos para el consumo del modelo. Contiene los subdirectorios `data_1`, `data_2` (filtrados) y `split` (conjuntos finales). |
| **`notebooks/`** | Entorno para la experimentaciÃ³n, EDA, y prototipado inicial. |
| **`models/exported/`** | Directorio para la versiÃ³n final del modelo (ej., `final_model.h5`) que estÃ¡ lista para el despliegue. |
| **`src/adapters/data_loader.py`** | Componente de abstracciÃ³n de datos. Encargado de cargar las imÃ¡genes desde el disco a memoria (`PIL.Image`) desde mÃºltiples fuentes (`data_1`, `data_2`). |
| **`src/builders/builders.py`** | FactorÃ­a de modelos. Define la arquitectura de la cabeza de clasificaciÃ³n y ensambla el modelo completo (VGG16 + cabeza), listo para la bÃºsqueda de hiperparÃ¡metros con Keras Tuner. |
| **`src/core/load_env.py`** | Utilidad de configuraciÃ³n. Carga y parsea de forma segura todas las variables de entorno (rutas, ratios, tamaÃ±os de imagen) desde el archivo `.env`. |
| **`src/pipelines/train.py`** | Script de orquestaciÃ³n central. Ejecuta la bÃºsqueda de Keras Tuner, aplica *Early Stopping* y registra todos los resultados en MLflow. |
| **`src/pipelines/preprocess.py`** | Script principal del *pipeline* de datos. Dirige el filtrado, la unificaciÃ³n, la divisiÃ³n estratificada y el balanceo (submuestreo/sobremuestreo) de los datos. |
| **`src/pipelines/infer.py`** | Pipeline de inferencia optimizado para el servidor. Carga el modelo final y contiene la funciÃ³n **`predict()`** utilizada por la API para clasificar imÃ¡genes. |
| **`src/utils/aug_detectors.py`** | Implementa la lÃ³gica de **De-AugmentaciÃ³n**; contiene las funciones para la generaciÃ³n de *embeddings* y el cÃ¡lculo de la similitud del coseno para detectar duplicados. |
| **`src/utils/data_augmentator.py`** | Define las funciones para las transformaciones espaciales complejas utilizadas durante el *oversampling* controlado. |
| **`src/utils/image_modifier.py`** | Contiene funciones de bajo nivel para las transformaciones de *calidad* de imagen (ej., ruido, brillo, contraste) utilizadas en el *Data Augmentation*. |
