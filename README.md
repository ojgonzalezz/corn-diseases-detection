# ğŸŒ½ DetecciÃ³n de Enfermedades del MaÃ­z con Transfer Learning

Sistema de Deep Learning para clasificaciÃ³n de enfermedades en hojas de maÃ­z utilizando Transfer Learning con VGG16/ResNet50, completamente containerizado con Docker.

---

## ğŸ“‹ Resumen del Proyecto

Pipeline robusto de Deep Learning para diagnÃ³stico automÃ¡tico de enfermedades comunes en hojas de maÃ­z. El proyecto utiliza Transfer Learning con arquitecturas preentrenadas (VGG16/ResNet50), optimizaciÃ³n de hiperparÃ¡metros con Keras Tuner, y seguimiento de experimentos con MLflow.

**CaracterÃ­sticas Principales:**
- ğŸ³ **100% Containerizado** - Solo necesitas Docker
- ğŸ¤– Transfer Learning con VGG16/ResNet50
- ğŸ¯ OptimizaciÃ³n con Keras Tuner
- ğŸ“Š Tracking de experimentos con MLflow
- ğŸš€ API REST con FastAPI
- âœ… Suite completa de tests automatizados
- ğŸ“¦ GestiÃ³n de configuraciÃ³n con Pydantic

---

## ğŸ¯ Clases de Enfermedades

El modelo clasifica 4 categorÃ­as:

1. **Blight** (TizÃ³n)
2. **Common_Rust** (Roya ComÃºn)
3. **Gray_Leaf_Spot** (Mancha Gris)
4. **Healthy** (Saludable)

---

## ğŸ“ Estructura del Proyecto

```
corn-diseases-detection/
â”œâ”€â”€ data/                       # Dataset (ignorado por git)
â”‚   â”œâ”€â”€ train/                  # 3,856 imÃ¡genes (balanceado)
â”‚   â”œâ”€â”€ val/                    # 716 imÃ¡genes (estratificado)
â”‚   â””â”€â”€ test/                   # 722 imÃ¡genes (estratificado)
â”‚
â”œâ”€â”€ src/                        # CÃ³digo fuente
â”‚   â”œâ”€â”€ adapters/               # Cargadores de datos
â”‚   â”œâ”€â”€ api/                    # API REST (FastAPI)
â”‚   â”œâ”€â”€ builders/               # Constructores de modelos
â”‚   â”œâ”€â”€ core/                   # ConfiguraciÃ³n central
â”‚   â”œâ”€â”€ pipelines/              # Pipelines ML (train, infer, preprocess)
â”‚   â””â”€â”€ utils/                  # Utilidades
â”‚
â”œâ”€â”€ tests/                      # Suite de tests (10 archivos)
â”‚
â”œâ”€â”€ experimentation/            # Scripts EDA y notebooks
â”‚
â”œâ”€â”€ experiments/                # ğŸ†• Experimentos edge computing
â”‚   â””â”€â”€ edge_models/            # Entrenamiento arquitecturas livianas
â”‚       â”œâ”€â”€ train_edge_model.py
â”‚       â”œâ”€â”€ train_all_models.py
â”‚       â”œâ”€â”€ compare_models.py
â”‚       â”œâ”€â”€ select_best_model.py
â”‚       â”œâ”€â”€ README.md
â”‚       â””â”€â”€ best_edge_model.json  # Salida: mejor modelo seleccionado
â”‚
â”œâ”€â”€ models/                     # Modelos entrenados (ignorado por git)
â”‚   â”œâ”€â”€ exported/               # Modelos finales (.keras)
â”‚   â”œâ”€â”€ mlruns/                 # Tracking MLflow
â”‚   â””â”€â”€ tuner_checkpoints/      # Keras Tuner
â”‚
â”œâ”€â”€ docker-compose.yml          # OrquestaciÃ³n de servicios
â”œâ”€â”€ Dockerfile                  # Imagen multi-stage optimizada
â”œâ”€â”€ requirements.txt            # Dependencias Python
â””â”€â”€ README.md                   # Este archivo
```

---

## ğŸš€ Inicio RÃ¡pido

### Requisitos

- **Docker Desktop** instalado ([Descargar](https://www.docker.com/products/docker-desktop))
- **Git** para clonar el repositorio
- **Datos** en `data/train`, `data/val`, `data/test`

---

## ğŸ”¬ **NUEVO: Experimentos Edge Computing**

### Entrenamiento de Arquitecturas Livianas

El proyecto incluye un sistema completo para evaluar **4 familias de arquitecturas** optimizadas para edge computing:

**Arquitecturas evaluadas:**
- **MobileNetV3** (Small y Large)
- **EfficientNet-Lite** (B0, B1, B2)
- **MobileViT** (Mobile Vision Transformer)
- **PMVT** (Plant-based Mobile Vision Transformer)

### Ejecutar Experimentos Completos

```bash
# Entrenar TODAS las arquitecturas edge automÃ¡ticamente
docker-compose --profile edge-experiments up
```

Esto ejecuta:
1. âœ… Entrenamiento de 7 arquitecturas livianas
2. âœ… ComparaciÃ³n automÃ¡tica de resultados
3. âœ… SelecciÃ³n del mejor modelo
4. âœ… GeneraciÃ³n de `best_edge_model.json`

**Criterios de selecciÃ³n:**
- PrecisiÃ³n global â‰¥ 85%
- Recall por clase â‰¥ 0.80
- Mejor balance precisiÃ³n/tamaÃ±o

**Salida:** `experiments/edge_models/best_edge_model.json`

### Ver Resultados

```bash
# MLflow UI para ver todos los experimentos
docker-compose --profile mlflow up -d
open http://localhost:5000

# Buscar experimento: "edge_models_comparison"
```

ğŸ“– **DocumentaciÃ³n completa:** `experiments/edge_models/README.md`

### 1. Clonar Repositorio

```bash
git clone https://github.com/ojgonzalezz/corn-diseases-detection.git
cd corn-diseases-detection
```

### 2. Construir Imagen Docker

```bash
# Construir imagen (incluye TensorFlow, Keras, MLflow)
docker-compose build
```

Esto instalarÃ¡ automÃ¡ticamente:
- TensorFlow 2.20.0
- Keras 3.11.3
- MLflow 3.3.2
- FastAPI + todas las dependencias

### 3. Entrenar Modelo

```bash
# Entrenar modelo con tus datos
docker-compose --profile training up

# O en background
docker-compose --profile training up -d

# Ver logs
docker-compose logs -f training
```

El modelo se guardarÃ¡ en `models/exported/best_VGG16.keras`

### 4. Iniciar API de Inferencia

```bash
# Iniciar API
docker-compose --profile api up -d

# Acceder a documentaciÃ³n
open http://localhost:8000/docs
```

### 5. Ver Experimentos en MLflow

```bash
# Iniciar MLflow UI
docker-compose --profile mlflow up -d

# Acceder a dashboard
open http://localhost:5000
```

---

## ğŸ³ Servicios Docker Disponibles

| Servicio | Profile | Puerto | Comando | DescripciÃ³n |
|----------|---------|--------|---------|-------------|
| **training** | `training` | - | `docker-compose --profile training up` | Entrenamiento estÃ¡ndar |
| **edge-experiments** | `edge-experiments` | - | `docker-compose --profile edge-experiments up` | ğŸ†• Entrenar modelos edge |
| **api** | `api` | 8000 | `docker-compose --profile api up -d` | API REST predicciones |
| **mlflow** | `mlflow` | 5000 | `docker-compose --profile mlflow up -d` | UI experimentos |
| **notebook** | `notebook` | 8888 | `docker-compose --profile notebook up -d` | Jupyter Lab |
| **preprocessing** | `preprocessing` | - | `docker-compose --profile preprocessing up` | Preprocesar datos |
| **evaluation** | `evaluation` | - | `docker-compose --profile evaluation up` | Evaluar modelos |

---

## ğŸ“¡ Uso de la API

### Endpoints Disponibles

**Health Check:**
```bash
curl http://localhost:8000/health
```

**InformaciÃ³n del Modelo:**
```bash
curl http://localhost:8000/info
```

**PredicciÃ³n Individual:**
```bash
curl -X POST http://localhost:8000/predict \
  -F "file=@ruta/a/imagen.jpg"
```

**PredicciÃ³n por Lotes:**
```bash
curl -X POST http://localhost:8000/batch-predict \
  -F "files=@imagen1.jpg" \
  -F "files=@imagen2.jpg" \
  -F "files=@imagen3.jpg"
```

### Ejemplo Python

```python
import requests

# PredicciÃ³n
with open('hoja_maiz.jpg', 'rb') as f:
    response = requests.post(
        'http://localhost:8000/predict',
        files={'file': f}
    )

result = response.json()
print(f"PredicciÃ³n: {result['prediction']['predicted_label']}")
print(f"Confianza: {result['prediction']['confidence']:.2%}")
```

---

## âš™ï¸ ConfiguraciÃ³n

### Variables de Entorno

El proyecto usa un archivo `.env` para configuraciÃ³n. Todas las variables tienen valores por defecto en `src/core/.env_example`.

**Variables Principales:**

| Variable | Valor por Defecto | DescripciÃ³n |
|----------|-------------------|-------------|
| `IMAGE_SIZE` | `(224, 224)` | Dimensiones de entrada |
| `NUM_CLASSES` | `4` | NÃºmero de clases |
| `BATCH_SIZE` | `32` | TamaÃ±o del batch |
| `MAX_EPOCHS` | `20` | Ã‰pocas mÃ¡ximas |
| `BACKBONE` | `VGG16` | Arquitectura base |
| `BALANCE_STRATEGY` | `oversample` | Estrategia de balanceo |

Para personalizar, edita `src/core/.env`

---

## ğŸ§ª Testing

### Ejecutar Tests en Docker

```bash
# Todos los tests
docker-compose run --rm training pytest tests/ -v

# Tests especÃ­ficos
docker-compose run --rm training pytest tests/test_train.py -v

# Tests sin mÃ³dulos lentos
docker-compose run --rm training pytest tests/ -m "not slow" -v
```

### Cobertura de Tests

El proyecto incluye **10 archivos de tests** con **~90% de cobertura**:
- `test_train.py` - Pipeline de entrenamiento
- `test_infer.py` - Pipeline de inferencia
- `test_preprocess.py` - Preprocesamiento
- `test_augmentation.py` - AugmentaciÃ³n de datos
- `test_config.py` - Sistema de configuraciÃ³n
- `test_builders.py` - Constructores de modelos
- `test_data_loader.py` - Carga de datos
- `test_logger.py` - Sistema de logging
- `test_paths.py` - GestiÃ³n de rutas
- `test_api.py` - Endpoints de API

---

## ğŸ”§ Comandos Docker Ãštiles

### GestiÃ³n de Contenedores

```bash
# Ver contenedores corriendo
docker-compose ps

# Ver logs
docker-compose logs -f [servicio]

# Detener todos los servicios
docker-compose down

# Detener y eliminar volÃºmenes (âš ï¸ elimina datos)
docker-compose down -v

# Reconstruir imagen desde cero
docker-compose build --no-cache
```

### Comandos Ãšnicos

```bash
# Ejecutar cualquier comando en el contenedor
docker-compose run --rm training python -m src.pipelines.train

# Shell interactiva
docker-compose run --rm training bash

# Verificar versiÃ³n de TensorFlow
docker-compose run --rm training python -c "import tensorflow as tf; print(tf.__version__)"
```

---

## ğŸ¨ PersonalizaciÃ³n del Entrenamiento

### Entrenar con Diferente Backbone

Edita `src/core/.env`:
```bash
BACKBONE=ResNet50
```

Luego ejecuta:
```bash
docker-compose --profile training up
```

### Ajustar HiperparÃ¡metros

Edita `src/core/.env`:
```bash
BATCH_SIZE=64
MAX_EPOCHS=50
MAX_TRIALS=20
BALANCE_STRATEGY=downsample
```

---

## ğŸ“Š Estructura de Datos

### Formato Esperado

El proyecto soporta dos estructuras:

**OpciÃ³n 1: Datos Ya Divididos (Recomendado)**
```
data/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ Blight/
â”‚   â”œâ”€â”€ Common_Rust/
â”‚   â”œâ”€â”€ Gray_Leaf_Spot/
â”‚   â””â”€â”€ Healthy/
â”œâ”€â”€ val/
â”‚   â””â”€â”€ ...
â””â”€â”€ test/
    â””â”€â”€ ...
```

**OpciÃ³n 2: Datos Raw para Preprocesar**
```
data/
â””â”€â”€ raw/
    â”œâ”€â”€ data_1/
    â”‚   â””â”€â”€ [clases]/
    â””â”€â”€ data_2/
        â””â”€â”€ [clases]/
```

Si tienes datos raw, ejecuta:
```bash
docker-compose --profile preprocessing up
```

---

## ğŸ” CaracterÃ­sticas Avanzadas

### De-augmentaciÃ³n Inteligente

El sistema detecta y filtra imÃ¡genes duplicadas usando embeddings de ResNet50:

```bash
# Configurar umbral en src/core/.env
IM_SIM_THRESHOLD=0.95  # 0.0 a 1.0 (mÃ¡s alto = mÃ¡s estricto)
```

### Balanceo de Clases

Tres estrategias disponibles:

1. **Oversample** (por defecto) - Aumenta clases minoritarias
2. **Downsample** - Reduce clases mayoritarias
3. **None** - Sin balanceo

```bash
# En src/core/.env
BALANCE_STRATEGY=oversample
```

### Tracking con MLflow

Todos los experimentos se registran automÃ¡ticamente:
- HiperparÃ¡metros
- MÃ©tricas (accuracy, loss)
- Modelos entrenados
- ConfiguraciÃ³n completa

```bash
# Ver experimentos
docker-compose --profile mlflow up -d
open http://localhost:5000
```

---

## ğŸ¯ Versionado de Modelos

Los modelos se guardan automÃ¡ticamente con:

```
models/exported/
â”œâ”€â”€ VGG16_20251002_143022_acc0.9745.keras    # Con timestamp + accuracy
â”œâ”€â”€ VGG16_20251002_143022_metadata.json      # Metadatos de entrenamiento
â””â”€â”€ best_VGG16.keras                         # Ãšltimo mejor modelo
```

Los metadatos incluyen:
- Timestamp
- Accuracy y loss en test
- HiperparÃ¡metros utilizados
- ConfiguraciÃ³n completa

---

## ğŸ› Troubleshooting Docker

### Error: "Cannot connect to Docker daemon"
```bash
# Iniciar Docker Desktop en Mac
# Verificar que estÃ¡ corriendo en la barra de menÃº
```

### Error: "Port already in use"
```bash
# Cambiar puerto en docker-compose.yml
ports:
  - "8001:8000"  # API en puerto 8001
```

### Limpiar Sistema Docker
```bash
# Limpiar contenedores detenidos
docker system prune

# Ver uso de espacio
docker system df

# Eliminar todo (âš ï¸ cuidado)
docker system prune -a
```

### Problemas de Memoria
```bash
# Editar docker-compose.yml para limitar recursos
services:
  training:
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
```

---

## ğŸ“ˆ Workflow TÃ­pico

### 1. Preparar Datos
```bash
# Si tienes datos raw
docker-compose --profile preprocessing up

# Verifica estructura en data/train, data/val, data/test
```

### 2. Entrenar Modelo
```bash
# Entrenar
docker-compose --profile training up

# El mejor modelo se guarda automÃ¡ticamente
```

### 3. Evaluar Modelo
```bash
# Evaluar modelo guardado
docker-compose --profile evaluation up
```

### 4. Desplegar API
```bash
# Iniciar API
docker-compose --profile api up -d

# Probar
curl http://localhost:8000/health
```

### 5. Hacer Predicciones
```bash
# Via API
curl -X POST http://localhost:8000/predict \
  -F "file=@imagen_hoja.jpg"

# Verifica en:
open http://localhost:8000/docs
```

---

## ğŸ§¬ Arquitectura del Sistema

### Pipeline de Datos
1. **Carga** - `src/adapters/data_loader.py`
2. **Preprocesamiento** - `src/pipelines/preprocess.py`
   - DetecciÃ³n de duplicados por embeddings
   - DivisiÃ³n estratificada
   - Balanceo de clases (oversample/downsample)
3. **AugmentaciÃ³n** - `src/utils/data_augmentator.py`

### Pipeline de Entrenamiento
1. **ConstrucciÃ³n** - `src/builders/builders.py`
   - Carga backbone (VGG16/ResNet50)
   - Ensambla cabeza de clasificaciÃ³n
2. **Tuning** - Keras Tuner con Hyperband
3. **Tracking** - MLflow registra todo
4. **Guardado** - Versionado automÃ¡tico

### Pipeline de Inferencia
1. **Carga** - `src/pipelines/infer.py`
2. **API** - `src/api/main.py`
   - Endpoint `/predict`
   - Endpoint `/batch-predict`
3. **Respuesta** - JSON con probabilidades

---

## ğŸ“Š Sistema de ConfiguraciÃ³n

### GestiÃ³n Centralizada con Pydantic

```python
from src.core.config import config

# Acceso type-safe
image_size = config.data.image_size        # (224, 224)
batch_size = config.training.batch_size    # 32
backbone = config.training.backbone        # 'VGG16'
```

ValidaciÃ³n automÃ¡tica de:
- Tipos de datos
- Rangos de valores
- Consistencia entre variables

---

## ğŸ§ª Testing Automatizado

**Cobertura:** ~90%  
**Tests:** 10 archivos, 3,000+ lÃ­neas

```bash
# Ejecutar todos los tests
docker-compose run --rm training pytest tests/ -v

# Con detalles
docker-compose run --rm training pytest tests/ -vv

# Solo tests rÃ¡pidos
docker-compose run --rm training pytest tests/ -m "not slow"
```

---

## ğŸ” Seguridad

- âœ… Contenedores corren con usuario no-root
- âœ… Variables sensibles en `.env` (no commiteado)
- âœ… Multi-stage build minimiza superficie de ataque
- âœ… Dependencias con versiones fijas

---

## ğŸ“¦ VolÃºmenes Docker

Los datos y modelos persisten entre reinicios:

```yaml
volumes:
  - ./data:/app/data           # Datos
  - ./models:/app/models       # Modelos entrenados
  - ./src:/app/src             # CÃ³digo (solo lectura)
```

**Nota:** Los modelos entrenados se guardan en tu mÃ¡quina local en `./models/`

---

## ğŸ›ï¸ ConfiguraciÃ³n Avanzada

### GPU Support (NVIDIA)

Descomentar en `docker-compose.yml`:

```yaml
training:
  deploy:
    resources:
      reservations:
        devices:
          - driver: nvidia
            count: 1
            capabilities: [gpu]
```

Requiere: [NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html)

### Limitar Recursos

```yaml
training:
  deploy:
    resources:
      limits:
        cpus: '4.0'
        memory: 8G
```

---

## ğŸŒ Despliegue en ProducciÃ³n

### Cloud Run (Google Cloud)

```bash
# Build y deploy
gcloud builds submit --tag gcr.io/PROJECT-ID/corn-api
gcloud run deploy corn-api \
  --image gcr.io/PROJECT-ID/corn-api \
  --platform managed \
  --region us-central1 \
  --memory 4Gi
```

### AWS ECS

```bash
# Push a ECR
aws ecr get-login-password | docker login --username AWS --password-stdin ECR_URL
docker tag corn-diseases-detection:latest ECR_URL/corn-api:latest
docker push ECR_URL/corn-api:latest

# Deploy en ECS (usar consola o Terraform)
```

### Heroku

```bash
heroku create corn-diseases-detection
heroku stack:set container
git push heroku main
```

---

## ğŸ“š Uso ProgramÃ¡tico

### Pipeline de Inferencia

```python
from src.pipelines.infer import predict

# Cargar imagen
with open('hoja_maiz.jpg', 'rb') as f:
    image_bytes = f.read()

# Predecir
result = predict(image_bytes)

print(f"Enfermedad: {result['predicted_label']}")
print(f"Confianza: {result['confidence']:.2%}")
print(f"Probabilidades: {result['all_probabilities']}")
```

### Pipeline de Entrenamiento

```python
from src.pipelines.train import train

# Entrenar con parÃ¡metros personalizados
tuner, (X_test, y_test) = train(
    backbone_name='ResNet50',
    split_ratios=(0.7, 0.15, 0.15),
    balanced='oversample'
)
```

---

## ğŸ› ï¸ Desarrollo

### Ejecutar Tests

```bash
docker-compose run --rm training pytest tests/ -v
```

### Acceder al Contenedor

```bash
# Shell interactiva
docker-compose run --rm training bash

# Explorar estructura
ls -la /app/src
```

### Jupyter para ExperimentaciÃ³n

```bash
# Iniciar Jupyter Lab
docker-compose --profile notebook up -d

# Acceder
open http://localhost:8888

# Notebooks en: experimentation/notebooks/
```

---

## ğŸ“Š Monitoreo

### Logs de Contenedores

```bash
# Logs en tiempo real
docker-compose logs -f training

# Ãšltimas 100 lÃ­neas
docker-compose logs --tail=100 api

# Todos los servicios
docker-compose logs -f
```

### Health Checks

```bash
# API
curl http://localhost:8000/health

# MLflow
curl http://localhost:5000/health

# En scripts
docker-compose ps
```

---

## ğŸ“– DocumentaciÃ³n Adicional

- **API Docs:** http://localhost:8000/docs (Swagger)
- **API ReDoc:** http://localhost:8000/redoc
- **MLflow UI:** http://localhost:5000
- **OpenAPI Schema:** http://localhost:8000/openapi.json

---

## ğŸ¤ Contribuir

1. Fork el repositorio
2. Crea una rama (`git checkout -b feature/nueva-funcionalidad`)
3. Haz tus cambios
4. Ejecuta tests: `docker-compose run --rm training pytest tests/`
5. Commit (`git commit -m 'feat: nueva funcionalidad'`)
6. Push (`git push origin feature/nueva-funcionalidad`)
7. Abre un Pull Request

---

## ğŸ“ Licencia

Este proyecto estÃ¡ bajo la licencia MIT.

---

## ğŸ†˜ Soporte

- **Issues:** [GitHub Issues](https://github.com/ojgonzalezz/corn-diseases-detection/issues)
- **Repository:** [ojgonzalezz/corn-diseases-detection](https://github.com/ojgonzalezz/corn-diseases-detection)

---

**ğŸŒ½ Desarrollado con Transfer Learning y Docker para mÃ¡xima reproducibilidad**
