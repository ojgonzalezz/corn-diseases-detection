-----

# DetecciÃ³n de Enfermedades del MaÃ­z con Transfer Learning

-----

## Resumen del Proyecto

Este proyecto implementa un pipeline de Deep Learning robusto para la clasificaciÃ³n de enfermedades comunes en hojas de maÃ­z. El objetivo es diagnosticar automÃ¡ticamente la salud de las plantas utilizando tÃ©cnicas de Transfer Learning basadas en la arquitectura VGG16, optimizando la cabeza de clasificaciÃ³n mediante Keras Tuner y rastreando todos los experimentos con MLflow.

El proyecto se destaca por su rigurosa estrategia de preprocesamiento, que aborda activamente el sesgo por duplicaciÃ³n (data leakage) y el desbalance de clases en un dataset bimodal compuesto por dos fuentes de datos distintas.

**CaracterÃ­sticas Principales:**
- Transfer Learning con VGG16/ResNet50
- De-augmentaciÃ³n inteligente usando embeddings de ResNet50
- Balanceo avanzado de clases (oversample/downsample)
- Seguimiento de experimentos con MLflow
- OptimizaciÃ³n de hiperparÃ¡metros con Keras Tuner
- GestiÃ³n de configuraciÃ³n validada con Pydantic
- Sistema de logging profesional con colores
- Suite completa de tests con pytest
- Manejo robusto de excepciones con sugerencias de recuperaciÃ³n

-----

## Problema y Contexto

Las enfermedades del maÃ­z, como la roya comÃºn, el tizÃ³n foliar y la mancha gris, representan una amenaza crÃ­tica para la seguridad alimentaria. El diagnÃ³stico tradicional mediante inspecciÃ³n visual es un proceso lento, subjetivo y dependiente de la pericia del observador. Este proyecto busca validar la viabilidad de un sistema de diagnÃ³stico automatizado mediante Inteligencia Artificial para superar estas limitaciones.

-----

## Objetivo y Tipos de Datos

### Objetivo Principal

Desarrollar un modelo de clasificaciÃ³n de imÃ¡genes altamente preciso y generalizable, capaz de diferenciar entre las siguientes cuatro categorÃ­as de salud de las hojas de maÃ­z:

1. **Blight**
2. **Common_Rust**
3. **Gray_Leaf_Spot**
4. **Healthy**

### Tipos de Datos

El dataset estÃ¡ compuesto por imÃ¡genes RGB de hojas de maÃ­z, recopiladas de dos fuentes distintas que se manejan por separado para controlar el Data Augmentation:

| Fuente | DescripciÃ³n | ConsideraciÃ³n |
| :--- | :--- | :--- |
| **data_1** | Dataset limpio, sin aumentaciÃ³n sintÃ©tica | no-augmentation |
| **data_2** | Dataset con aumentaciÃ³n sintÃ©tica aplicada | augmented |

-----

## Estructura Detallada del Repositorio

El proyecto sigue una estructura modular y escalable para separar el cÃ³digo de producciÃ³n (src), los datos (data), y la experimentaciÃ³n (experimentation).

```
corn-diseases-detection/
â”œâ”€â”€ data/                     # Directorio de dataset (ignorado por git)
â”‚   â”œâ”€â”€ train/                # Conjunto de entrenamiento (3,856 imÃ¡genes - balanceado)
â”‚   â”‚   â”œâ”€â”€ Blight/           # 964 imÃ¡genes
â”‚   â”‚   â”œâ”€â”€ Common_Rust/      # 964 imÃ¡genes
â”‚   â”‚   â”œâ”€â”€ Gray_Leaf_Spot/   # 964 imÃ¡genes
â”‚   â”‚   â””â”€â”€ Healthy/          # 964 imÃ¡genes
â”‚   â”œâ”€â”€ val/                  # Conjunto de validaciÃ³n (716 imÃ¡genes - estratificado)
â”‚   â”‚   â”œâ”€â”€ Blight/           # 171 imÃ¡genes
â”‚   â”‚   â”œâ”€â”€ Common_Rust/      # 195 imÃ¡genes
â”‚   â”‚   â”œâ”€â”€ Gray_Leaf_Spot/   # 176 imÃ¡genes
â”‚   â”‚   â””â”€â”€ Healthy/          # 174 imÃ¡genes
â”‚   â””â”€â”€ test/                 # Conjunto de prueba (722 imÃ¡genes - estratificado)
â”‚       â”œâ”€â”€ Blight/           # 173 imÃ¡genes
â”‚       â”œâ”€â”€ Common_Rust/      # 197 imÃ¡genes
â”‚       â”œâ”€â”€ Gray_Leaf_Spot/   # 177 imÃ¡genes
â”‚       â””â”€â”€ Healthy/          # 175 imÃ¡genes
â”‚
â”œâ”€â”€ experimentation/          # Scripts de EDA y exploraciÃ³n
â”‚   â”œâ”€â”€ eda/                  # ValidaciÃ³n y anÃ¡lisis de datos
â”‚   â”‚   â”œâ”€â”€ analyze_feature.py
â”‚   â”‚   â”œâ”€â”€ explore_distribution.py
â”‚   â”‚   â”œâ”€â”€ validate_dataset.py
â”‚   â”‚   â””â”€â”€ view_samples.py
â”‚   â””â”€â”€ notebooks/
â”‚       â””â”€â”€ 01_eda_exploration.ipynb
â”‚
â”œâ”€â”€ models/                   # Artefactos de modelos (ignorado por git)
â”‚   â”œâ”€â”€ mlruns/               # Seguimiento de experimentos con MLflow
â”‚   â”œâ”€â”€ tuner_checkpoints/    # BÃºsqueda de hiperparÃ¡metros con Keras Tuner
â”‚   â””â”€â”€ exported/             # Modelos finales entrenados (best_VGG16.keras, etc.)
â”‚
â”œâ”€â”€ src/                      # CÃ³digo fuente de producciÃ³n
â”‚   â”œâ”€â”€ adapters/
â”‚   â”‚   â””â”€â”€ data_loader.py    # AbstracciÃ³n: Carga de datos de mÃºltiples fuentes
â”‚   â”œâ”€â”€ builders/
â”‚   â”‚   â”œâ”€â”€ base_models.py    # DefiniciÃ³n de backbones preentrenados (VGG16)
â”‚   â”‚   â””â”€â”€ builders.py       # Ensamblaje de la cabeza de clasificaciÃ³n para Keras Tuner
â”‚   â”œâ”€â”€ core/                 # ConfiguraciÃ³n y utilidades de entorno
â”‚   â”‚   â”œâ”€â”€ load_env.py       # Carga de variables de entorno (.env)
â”‚   â”‚   â”œâ”€â”€ config.py         # GestiÃ³n de configuraciÃ³n con Pydantic (validaciÃ³n)
â”‚   â”‚   â””â”€â”€ path_finder.py    # DetecciÃ³n de la ruta raÃ­z del proyecto
â”‚   â”œâ”€â”€ pipelines/            # Scripts del ciclo de Machine Learning
â”‚   â”‚   â”œâ”€â”€ data_pipeline.py  # GeneraciÃ³n de DataGenerators para Keras
â”‚   â”‚   â”œâ”€â”€ evaluate_finetuned.py
â”‚   â”‚   â”œâ”€â”€ train.py          # OrquestaciÃ³n del entrenamiento con Keras Tuner/MLflow
â”‚   â”‚   â”œâ”€â”€ preprocess.py     # Script principal de filtrado, unificaciÃ³n y balanceo
â”‚   â”‚   â””â”€â”€ infer.py          # LÃ³gica de inferencia para la API (clasificaciÃ³n)
â”‚   â””â”€â”€ utils/                # Funciones de ayuda
â”‚       â”œâ”€â”€ aug_detectors.py    # DetecciÃ³n y filtrado de aumentaciones por Embedding
â”‚       â”œâ”€â”€ data_augmentator.py # Transformaciones espaciales para Oversampling
â”‚       â”œâ”€â”€ image_modifier.py   # Transformaciones de calidad (brillo, contraste, ruido)
â”‚       â”œâ”€â”€ utils.py            # Utilidades miscelÃ¡neas (flatten_data, split, etc.)
â”‚       â”œâ”€â”€ paths.py            # Manejo centralizado de rutas del proyecto
â”‚       â”œâ”€â”€ logger.py           # Sistema de logging profesional con colores
â”‚       â””â”€â”€ exceptions.py       # Excepciones personalizadas con sugerencias
â”‚
â”œâ”€â”€ tests/                    # Suite de pruebas con pytest
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py           # Fixtures compartidas
â”‚   â”œâ”€â”€ test_preprocess.py    # Tests de preprocesamiento y split
â”‚   â””â”€â”€ test_augmentation.py  # Tests de augmentaciÃ³n de imÃ¡genes
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ pyproject.toml            # ConfiguraciÃ³n del proyecto (PEP 518)
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

### Nota sobre el Flujo de Datos

**Estructura Actual:** El proyecto utiliza datos pre-divididos en los directorios `data/train/`, `data/val/`, `data/test/`. Esta es la estructura de trabajo real.

**JustificaciÃ³n:** Los datos ya han sido preprocesados, balanceados y divididos usando el pipeline de preprocesamiento en `src/pipelines/preprocess.py`. La divisiÃ³n es:
- **Entrenamiento:** 70% (3,856 imÃ¡genes - perfectamente balanceado en 4 clases)
- **ValidaciÃ³n:** 15% (716 imÃ¡genes - estratificado)
- **Prueba:** 15% (722 imÃ¡genes - estratificado)

### DescripciÃ³n Profesional de MÃ³dulos y Scripts

| Carpeta/Script | DescripciÃ³n |
| :--- | :--- |
| **`data/train/`** | Dataset de entrenamiento con clases balanceadas (964 imÃ¡genes por clase) |
| **`data/val/`** | Dataset de validaciÃ³n con divisiÃ³n estratificada para evaluaciÃ³n del modelo |
| **`data/test/`** | Dataset de prueba para evaluaciÃ³n final del modelo |
| **`experimentation/`** | Scripts de EDA y notebooks de Jupyter para exploraciÃ³n |
| **`models/exported/`** | Modelos finales entrenados listos para inferencia (ej. `best_VGG16.keras`) |
| **`src/adapters/data_loader.py`** | Componente de abstracciÃ³n de datos. Encargado de cargar las imÃ¡genes desde el disco a memoria (PIL.Image) desde mÃºltiples fuentes (data_1, data_2). |
| **`src/builders/builders.py`** | FactorÃ­a de modelos. Define la arquitectura de la cabeza de clasificaciÃ³n y ensambla el modelo completo (VGG16 + cabeza), listo para la bÃºsqueda de hiperparÃ¡metros con Keras Tuner. |
| **`src/core/load_env.py`** | Utilidad de configuraciÃ³n. Carga y parsea de forma segura todas las variables de entorno (rutas, ratios, tamaÃ±os de imagen) desde el archivo `.env`. |
| **`src/pipelines/train.py`** | Script de orquestaciÃ³n central. Ejecuta la bÃºsqueda de Keras Tuner, aplica Early Stopping y registra todos los resultados en MLflow. |
| **`src/pipelines/preprocess.py`** | Script principal del pipeline de datos. Dirige el filtrado, la unificaciÃ³n, la divisiÃ³n estratificada y el balanceo (submuestreo/sobremuestreo) de los datos. |
| **`src/pipelines/infer.py`** | Pipeline de inferencia optimizado para el servidor. Carga el modelo final y contiene la funciÃ³n `predict()` utilizada por la API para clasificar imÃ¡genes. |
| **`src/utils/aug_detectors.py`** | Implementa la lÃ³gica de De-AugmentaciÃ³n; contiene las funciones para la generaciÃ³n de embeddings y el cÃ¡lculo de la similitud del coseno para detectar duplicados. |
| **`src/utils/data_augmentator.py`** | Define las funciones para las transformaciones espaciales complejas utilizadas durante el oversampling controlado. |
| **`src/utils/image_modifier.py`** | Contiene funciones de bajo nivel para las transformaciones de calidad de imagen (ej., ruido, brillo, contraste) utilizadas en el Data Augmentation. |

---

## Inicio RÃ¡pido

### OpciÃ³n 1: Usando Docker (Recomendado) ğŸ³

La forma mÃ¡s rÃ¡pida y reproducible de ejecutar el proyecto:

```bash
# Clonar el repositorio
git clone https://github.com/ojgonzalezz/corn-diseases-detection.git
cd corn-diseases-detection

# Configurar variables de entorno
cp src/core/.env_example src/core/.env

# Construir imagen Docker
docker-compose build

# Entrenar modelo
docker-compose --profile training up

# Ver experimentos en MLflow
docker-compose --profile mlflow up -d
# Acceder a http://localhost:5000
```

**âœ¨ Ventajas:**
- No necesitas instalar dependencias manualmente
- Entorno 100% reproducible
- Aislamiento completo del sistema host
- Funciona igual en cualquier sistema operativo

Ver la [secciÃ³n de Docker](#docker-y-contenedores) para mÃ¡s detalles.

### OpciÃ³n 2: InstalaciÃ³n Local

```bash
# Clonar el repositorio
git clone https://github.com/ojgonzalezz/corn-diseases-detection.git
cd corn-diseases-detection

# Crear entorno virtual
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt

# Configurar variables de entorno
cp src/core/.env_example src/core/.env
# Editar src/core/.env segÃºn tus necesidades (opcional)
```

**âš ï¸ IMPORTANTE:** El archivo `.env` es necesario para ejecutar el proyecto. Se ha creado automÃ¡ticamente con valores por defecto, pero puedes personalizarlo.

### Entrenamiento

```bash
# Entrenar modelo con configuraciÃ³n por defecto (VGG16, datos balanceados)
python -m src.pipelines.train

# Entrenar con un backbone especÃ­fico
python -c "from src.pipelines.train import train; train(backbone_name='ResNet50')"
```

### Inferencia

```python
from src.pipelines.infer import predict

# Cargar imagen como bytes
with open('ruta/a/hoja_maiz.jpg', 'rb') as f:
    image_bytes = f.read()

# Obtener predicciÃ³n
result = predict(image_bytes)
print(f"PredicciÃ³n: {result['predicted_label']}")
print(f"Confianza: {result['confidence']:.2%}")
```

### ConfiguraciÃ³n

El proyecto utiliza un archivo `.env` para toda la configuraciÃ³n. Para personalizar:

```bash
# Editar el archivo de configuraciÃ³n
nano src/core/.env  # o usar tu editor preferido
```

**Variables de ConfiguraciÃ³n Principales:**

| Variable | DescripciÃ³n | Valor por Defecto |
|----------|-------------|-------------------|
| `IMAGE_SIZE` | Dimensiones de entrada (ancho, alto) | `(224, 224)` |
| `NUM_CLASSES` | NÃºmero de clases a clasificar | `4` |
| `CLASS_NAMES` | Nombres de las clases | `['Blight', 'Common_Rust', 'Gray_Leaf_Spot', 'Healthy']` |
| `BATCH_SIZE` | TamaÃ±o del batch de entrenamiento | `32` |
| `MAX_EPOCHS` | Ã‰pocas mÃ¡ximas de entrenamiento | `20` |
| `MAX_TRIALS` | Trials de bÃºsqueda de hiperparÃ¡metros | `10` |
| `BACKBONE` | Arquitectura base del modelo | `VGG16` |
| `BALANCE_STRATEGY` | Estrategia de balanceo de clases | `oversample` |
| `SPLIT_RATIOS` | Ratios de divisiÃ³n (train/val/test) | `(0.7, 0.15, 0.15)` |
| `IM_SIM_THRESHOLD` | Umbral de similitud para de-augmentaciÃ³n | `0.95` |

**Consulta el archivo `src/core/.env_example` para ver todas las opciones disponibles con documentaciÃ³n completa.**

---

## CI/CD y AutomatizaciÃ³n

### GitHub Actions

El proyecto incluye workflows automÃ¡ticos para:

1. **Tests AutomÃ¡ticos** (`.github/workflows/tests.yml`)
   - Ejecuta en Python 3.9, 3.10, 3.11
   - Tests con pytest
   - Cobertura de cÃ³digo con Codecov
   - Se ejecuta en push y pull requests

2. **Linting y Formato** (`.github/workflows/linting.yml`)
   - Verifica formato con Black
   - Verifica imports con isort
   - Linting con Flake8
   - Type checking con mypy

3. **RevisiÃ³n de Dependencias** (`.github/workflows/dependency-review.yml`)
   - Detecta vulnerabilidades en dependencias
   - Solo en pull requests a main

### Badges de Estado

AÃ±ade estos badges a tu README:

```markdown
[![Tests](https://github.com/ojgonzalezz/corn-diseases-detection/workflows/Tests/badge.svg)](https://github.com/ojgonzalezz/corn-diseases-detection/actions)
[![Linting](https://github.com/ojgonzalezz/corn-diseases-detection/workflows/Linting%20y%20Formato/badge.svg)](https://github.com/ojgonzalezz/corn-diseases-detection/actions)
[![codecov](https://codecov.io/gh/ojgonzalezz/corn-diseases-detection/branch/main/graph/badge.svg)](https://codecov.io/gh/ojgonzalezz/corn-diseases-detection)
```

---

## Estrategia de Pruebas

El proyecto cuenta con una suite completa de pruebas usando pytest:

### Ejecutar Tests

```bash
# Ejecutar todos los tests
pytest

# Ejecutar con cobertura
pytest --cov=src --cov-report=html

# Ejecutar solo tests especÃ­ficos
pytest tests/test_preprocess.py
pytest tests/test_augmentation.py

# Ejecutar tests con verbosidad
pytest -v
```

### Tests Implementados

**Tests de Preprocesamiento (`test_preprocess.py`):**
- ValidaciÃ³n de ratios de divisiÃ³n estratificada
- VerificaciÃ³n de proporciones correctas en train/val/test
- Manejo de categorÃ­as vacÃ­as
- ValidaciÃ³n de la funciÃ³n `flatten_data`
- VerificaciÃ³n de dimensiones y tipos de datos

**Tests de AugmentaciÃ³n (`test_augmentation.py`):**
- PreservaciÃ³n de dimensiones tras transformaciones
- ValidaciÃ³n de cada mÃ©todo de `ImageAugmentor`
- Reproducibilidad con semillas fijas
- VerificaciÃ³n de valores de pÃ­xeles en rango vÃ¡lido
- Consistencia de etiquetas tras augmentaciÃ³n

**Scripts de EDA (validaciÃ³n adicional):**
```bash
# Validar integridad del dataset
python experimentation/eda/validate_dataset.py

# Verificar distribuciones de clases
python experimentation/eda/explore_distribution.py

# InspecciÃ³n visual de muestras
python experimentation/eda/view_samples.py
```

---

## Versionado de Modelos

**Versionado AutomÃ¡tico:** El pipeline de entrenamiento guarda automÃ¡ticamente los modelos con informaciÃ³n de versiÃ³n:

**ConvenciÃ³n de Nombres de Archivo:**
```
models/exported/
â”œâ”€â”€ VGG16_20250102_143022_acc0.9745.keras    # Con timestamp + precisiÃ³n
â”œâ”€â”€ VGG16_20250102_143022_metadata.json      # ConfiguraciÃ³n de entrenamiento
â””â”€â”€ best_VGG16.keras                         # Ãšltimo mejor modelo (para inferencia)
```

**Los Metadatos Incluyen:**
- Timestamp
- PrecisiÃ³n y pÃ©rdida en prueba
- HiperparÃ¡metros utilizados
- Ratios de divisiÃ³n de datos
- Estrategia de balanceo
- TamaÃ±o de imagen y nÃºmero de clases

**Registro de Modelos:** Todas las ejecuciones de entrenamiento se rastrean en MLflow en `models/mlruns/` para comparaciÃ³n de experimentos.

---

## CaracterÃ­sticas Avanzadas

### GestiÃ³n de ConfiguraciÃ³n con Pydantic

El proyecto utiliza Pydantic para validaciÃ³n robusta de configuraciÃ³n:

```python
from src.core.config import config

# Acceso type-safe a la configuraciÃ³n
image_size = config.data.image_size  # (224, 224)
batch_size = config.training.batch_size  # 32
class_names = config.data.class_names  # ['Blight', ...]

# ValidaciÃ³n automÃ¡tica de tipos y valores
# Si IMAGE_SIZE en .env es invÃ¡lido, se lanza una excepciÃ³n clara
```

**Beneficios:**
- ValidaciÃ³n automÃ¡tica de tipos
- Valores por defecto razonables
- Errores claros cuando la configuraciÃ³n es invÃ¡lida
- Autocompletado en IDEs

### Sistema de Logging Profesional

```python
from src.utils.logger import get_logger, log_section, log_dict

logger = get_logger(__name__)

logger.info("Iniciando entrenamiento...")
logger.warning("GPU no disponible, usando CPU")
logger.error("Error al cargar datos")

# Logging estructurado
log_section(logger, "ConfiguraciÃ³n de Entrenamiento")
log_dict(logger, {'lr': 0.001, 'epochs': 10}, "HiperparÃ¡metros")
```

**CaracterÃ­sticas:**
- Colores en terminal para mejor legibilidad
- Formato consistente en toda la aplicaciÃ³n
- OpciÃ³n de guardar logs en archivos
- Niveles de logging configurables

### Manejo Robusto de Excepciones

Todas las excepciones incluyen sugerencias de recuperaciÃ³n:

```python
from src.utils.exceptions import NoModelToLoadError, DatasetNotFoundError

try:
    model = load_model('model.keras')
except NoModelToLoadError as e:
    print(e)
    # Imprime:
    # "No se encontrÃ³ el modelo en: model.keras
    #
    # Sugerencia: Opciones:
    #   1. Entrenar un modelo ejecutando: python -m src.pipelines.train
    #   2. Verificar la ruta del modelo en la configuraciÃ³n
    #   ..."
```

**Excepciones Disponibles:**
- `DatasetNotFoundError`, `EmptyDatasetError`, `InvalidImageError`
- `NoModelToLoadError`, `ModelLoadError`, `InvalidBackboneError`
- `MissingConfigError`, `InvalidConfigError`, `NoLabelsError`
- `GPUNotAvailableError`, `InsufficientMemoryError`
- `TrainingDivergenceError`, `NoImprovementError`

### Manejo Centralizado de Rutas

```python
from src.utils.paths import paths

# Acceso limpio a rutas del proyecto
data_dir = paths.data_raw
models_dir = paths.models_exported
mlruns = paths.mlruns

# Crear directorios si no existen
paths.ensure_dir(paths.models_exported)

# Rutas relativas para logging
print(f"Guardando en: {paths.relative_to_root(model_path)}")
```

---

## InstalaciÃ³n y Desarrollo

### InstalaciÃ³n BÃ¡sica

```bash
# Clonar repositorio
git clone https://github.com/ojgonzalezz/corn-diseases-detection.git
cd corn-diseases-detection

# OpciÃ³n 1: Usando pip (recomendado - mÃ¡s rÃ¡pido)
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
pip install -r requirements.txt

# OpciÃ³n 2: Usando conda (si prefieres anaconda)
conda env create -f environment.yml
conda activate dl-gpu
```

**ğŸ“ Nota sobre GestiÃ³n de Dependencias:**

Este proyecto usa **`requirements.txt` como fuente principal** de dependencias. El archivo `environment.yml` estÃ¡ simplificado y referencia automÃ¡ticamente a `requirements.txt`, evitando duplicaciÃ³n y divergencia entre archivos.

### InstalaciÃ³n para Desarrollo

```bash
# Instalar con dependencias de desarrollo
pip install -e ".[dev]"

# Instalar todas las dependencias opcionales
pip install -e ".[all]"
```

### ConfiguraciÃ³n de Pre-commit Hooks

Pre-commit ejecuta automÃ¡ticamente validaciones antes de cada commit:

```bash
# Instalar herramientas de desarrollo
pip install -e ".[dev]"

# Configurar pre-commit
pre-commit install

# (Opcional) Ejecutar en todos los archivos
pre-commit run --all-files
```

**Hooks configurados:**
- âœ… Formateo automÃ¡tico (Black)
- âœ… Ordenamiento de imports (isort)
- âœ… Linting (Flake8)
- âœ… DetecciÃ³n de secretos
- âœ… Limpieza de notebooks Jupyter
- âœ… ValidaciÃ³n YAML/JSON

### Usando Makefile (Recomendado)

El proyecto incluye un Makefile para facilitar tareas comunes:

```bash
# Ver todos los comandos disponibles
make help

# Setup completo del proyecto
make setup

# Ejecutar tests
make test

# Ejecutar tests con cobertura
make test-cov

# Formatear cÃ³digo
make format

# Verificar calidad de cÃ³digo
make lint

# Ejecutar todas las validaciones de CI
make ci

# Entrenar modelo
make train

# Limpiar archivos temporales
make clean
```

---

## ResoluciÃ³n de Problemas

### Error: "No se encontrÃ³ el archivo .env"

```bash
# Copiar el archivo de ejemplo
cp src/core/.env_example src/core/.env
```

### Error: "ModuleNotFoundError: No module named 'pydantic_settings'"

```bash
# OpciÃ³n 1: pip (recomendado - mÃ¡s rÃ¡pido)
pip install -r requirements.txt

# OpciÃ³n 2: conda (actualiza el entorno existente)
conda env update -f environment.yml --prune
```

**ğŸ’¡ Tip:** El archivo `environment.yml` ahora usa `requirements.txt` como fuente principal, por lo que ambos mÃ©todos instalarÃ¡n las mismas dependencias. Recomendamos usar pip directamente para mayor rapidez.

### Error: "No se encontrÃ³ el dataset"

El proyecto soporta dos estructuras de datos:

**OpciÃ³n 1: Datos ya divididos (recomendado)**
```
data/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ Blight/
â”‚   â”œâ”€â”€ Common_Rust/
â”‚   â”œâ”€â”€ Gray_Leaf_Spot/
â”‚   â””â”€â”€ Healthy/
â”œâ”€â”€ val/
â”‚   â””â”€â”€ ...
â””â”€â”€ test/
    â””â”€â”€ ...
```

**OpciÃ³n 2: Datos raw para preprocesar**
```
data/
â””â”€â”€ raw/
    â”œâ”€â”€ data_1/
    â”‚   â”œâ”€â”€ Blight/
    â”‚   â””â”€â”€ ...
    â””â”€â”€ data_2/
        â”œâ”€â”€ Blight/
        â””â”€â”€ ...
```

Si tienes datos en `data/raw/`, ejecuta el pipeline de preprocesamiento:
```bash
python -m src.pipelines.preprocess
```

Si tus datos ya estÃ¡n divididos en `data/train/val/test/`, el proyecto los usarÃ¡ automÃ¡ticamente.

### Error: "GPU no disponible"

El proyecto funciona tanto en CPU como GPU. Para verificar disponibilidad de GPU:
```python
from src.utils.utils import check_cuda_availability

# Verificar solo TensorFlow (recomendado)
check_cuda_availability()

# Verificar tambiÃ©n PyTorch (requiere instalaciÃ³n manual)
check_cuda_availability(check_pytorch=True)
```

Para forzar el uso de CPU:
```python
import os
os.environ['CUDA_VISIBLE_DEVICES'] = '-1'
```

**Nota:** Este proyecto usa **solo TensorFlow**. PyTorch no estÃ¡ incluido en las dependencias para reducir el tamaÃ±o de instalaciÃ³n (~2GB). Si necesitas PyTorch para experimentaciÃ³n, instÃ¡lalo manualmente:
```bash
pip install torch torchvision torchaudio
```

### Verificar que la ConfiguraciÃ³n es Correcta

```python
from src.core.config import config

# Mostrar configuraciÃ³n actual
print(config.to_dict())
```

---

## Docker y Contenedores

El proyecto incluye soporte completo para Docker, proporcionando un entorno reproducible y aislado para entrenamiento, evaluaciÃ³n e inferencia.

### Arquitectura Docker

El proyecto utiliza:
- **Dockerfile multi-stage**: Optimiza tamaÃ±o de imagen (builder + runtime)
- **Docker Compose**: Orquesta mÃºltiples servicios con perfiles
- **VolÃºmenes persistentes**: Datos y modelos no se pierden al reiniciar contenedores
- **Usuario no-root**: Mejora seguridad del contenedor

### Servicios Disponibles

| Servicio | Profile | Puerto | DescripciÃ³n |
|----------|---------|--------|-------------|
| `training` | `training` | - | Entrenamiento de modelos con Keras Tuner |
| `preprocessing` | `preprocessing` | - | Preprocesamiento y divisiÃ³n de datos |
| `evaluation` | `evaluation` | - | EvaluaciÃ³n de modelos entrenados |
| `inference` | `inference`, `api` | 8000 | API de inferencia (FastAPI) |
| `mlflow` | `mlflow`, `monitoring` | 5000 | MLflow UI para seguimiento de experimentos |
| `notebook` | `development`, `notebook` | 8888 | Jupyter Lab para experimentaciÃ³n |

### Comandos Comunes

**Construir imagen:**
```bash
docker-compose build
```

**Entrenamiento:**
```bash
# Entrenar modelo (foreground)
docker-compose --profile training up

# Entrenar modelo (background)
docker-compose --profile training up -d

# Ver logs en tiempo real
docker-compose logs -f training
```

**MLflow UI:**
```bash
# Iniciar servidor MLflow
docker-compose --profile mlflow up -d

# Acceder a http://localhost:5000
# Ver experimentos, mÃ©tricas, y artefactos
```

**Jupyter Notebook:**
```bash
# Iniciar Jupyter Lab
docker-compose --profile notebook up -d

# Acceder a http://localhost:8888
# Notebooks en experimentation/notebooks/
```

**Preprocesamiento:**
```bash
docker-compose --profile preprocessing up
```

**API de Inferencia:**
```bash
# Iniciar API
docker-compose --profile api up -d

# Acceder a documentaciÃ³n: http://localhost:8000/docs
# Realizar predicciones: POST http://localhost:8000/predict
```

**Ejecutar comando Ãºnico:**
```bash
# Ejecutar cualquier comando en el contenedor
docker-compose run --rm training python -m src.pipelines.train

# Ver ayuda de un script
docker-compose run --rm training python -m src.pipelines.train --help

# Ejecutar tests
docker-compose run --rm training pytest tests/
```

**Limpiar:**
```bash
# Detener todos los contenedores
docker-compose down

# Detener y eliminar volÃºmenes (âš ï¸ elimina datos y modelos)
docker-compose down -v

# Eliminar imagen
docker-compose down --rmi all
```

### ConfiguraciÃ³n Avanzada

**Soporte GPU (NVIDIA):**

1. Instalar [NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html)

2. Descomentar en `docker-compose.yml`:
```yaml
training:
  deploy:
    resources:
      reservations:
        devices:
          - driver: nvidia
            count: 1
            capabilities: [gpu]
```

3. Ejecutar:
```bash
docker-compose --profile training up
```

**Limitar recursos:**

Editar `docker-compose.yml`:
```yaml
training:
  deploy:
    resources:
      limits:
        cpus: '4.0'      # 4 CPUs
        memory: 8G       # 8GB RAM
      reservations:
        memory: 4G       # Reservar mÃ­nimo 4GB
```

**VolÃºmenes personalizados:**

```bash
# Usar datos de una ubicaciÃ³n diferente
docker-compose run --rm \
  -v /ruta/a/mis/datos:/app/data:ro \
  training
```

### Mejores PrÃ¡cticas

1. **Desarrollo local + Docker para producciÃ³n**:
   - Desarrolla cÃ³digo localmente con tu IDE favorito
   - Usa Docker para entrenar y desplegar
   - Los volÃºmenes sincronizan automÃ¡ticamente cambios

2. **GestiÃ³n de datos**:
   - Monta `./data` como volumen (no se copia a imagen)
   - Modelos se guardan en `./models` (persistente)
   - Usa `.dockerignore` para excluir archivos grandes

3. **CI/CD**:
   - GitHub Actions puede construir y publicar imÃ¡genes
   - Usa multi-stage build para reducir tamaÃ±o
   - Cachea layers para builds mÃ¡s rÃ¡pidos

4. **Seguridad**:
   - Contenedores corren con usuario no-root
   - Nunca incluyas `.env` en la imagen
   - Usa secrets para credenciales sensibles

### Troubleshooting Docker

**Error: "Cannot connect to Docker daemon"**
```bash
# Iniciar Docker Desktop (macOS/Windows)
# O iniciar servicio (Linux)
sudo systemctl start docker
```

**Build muy lento:**
```bash
# Usar BuildKit para builds mÃ¡s rÃ¡pidos
DOCKER_BUILDKIT=1 docker-compose build
```

**Puerto en uso:**
```bash
# Cambiar puerto en docker-compose.yml
ports:
  - "5001:5000"  # MLflow en puerto 5001
```

**Espacio en disco:**
```bash
# Limpiar imÃ¡genes no utilizadas
docker system prune -a

# Ver uso de espacio
docker system df
```

---

## Licencia

Este proyecto estÃ¡ bajo la licencia MIT.

---

## Contacto

Para preguntas o colaboraciones, por favor contactar a los mantenedores del proyecto.
